"""
èµ„æºç›‘æ§æœåŠ¡

ç›‘æ§æ¶ˆæ¯ä¸­çš„èµ„æºé“¾æ¥ï¼Œæå–115/ç£åŠ›/ed2ké“¾æ¥ï¼Œè‡ªåŠ¨è½¬å­˜åˆ°115ç½‘ç›˜
"""
import json
import hashlib
import re
from datetime import timedelta
from typing import List, Dict, Optional, TYPE_CHECKING
from sqlalchemy import select, and_
from sqlalchemy.ext.asyncio import AsyncSession

from log_manager import get_logger
from database import get_db
from models import ResourceMonitorRule, ResourceRecord
from timezone_utils import get_user_now

if TYPE_CHECKING:
    from services.message_context import MessageContext

logger = get_logger("resource_monitor", "enhanced_bot.log")


class LinkExtractor:
    """é“¾æ¥æå–å™¨"""
    
    PATTERNS = {
        'pan115': [
            r'https?://(?:115|115cdn)\.com/s/[a-zA-Z0-9]+(?:\?password=[a-zA-Z0-9]+)?',
            r'115://[a-zA-Z0-9]+',
        ],
        'magnet': [
            r'magnet:\?xt=urn:btih:[a-zA-Z0-9]{32,40}[^\s]*',
        ],
        'ed2k': [
            r'ed2k://\|file\|[^\|]+\|[0-9]+\|[a-fA-F0-9]{32}\|[^\s]*',
        ]
    }
    
    @classmethod
    def extract_all(cls, text: str) -> Dict[str, List[str]]:
        """æå–æ‰€æœ‰ç±»å‹çš„é“¾æ¥"""
        results = {}
        for link_type, patterns in cls.PATTERNS.items():
            links = []
            for pattern in patterns:
                matches = re.findall(pattern, text, re.IGNORECASE)
                links.extend(matches)
            
            if links:
                results[link_type] = list(set(links))  # å»é‡
        
        return results
    
    @classmethod
    def calculate_hash(cls, link: str) -> str:
        """è®¡ç®—é“¾æ¥å“ˆå¸Œï¼ˆç”¨äºå»é‡ï¼‰"""
        return hashlib.md5(link.encode()).hexdigest()


class ResourceMonitorService:
    """
    èµ„æºç›‘æ§æœåŠ¡
    
    åŠŸèƒ½ï¼š
    1. ç›‘æ§æ¶ˆæ¯ä¸­çš„èµ„æºé“¾æ¥
    2. æå–115/ç£åŠ›/ed2ké“¾æ¥
    3. è‡ªåŠ¨è½¬å­˜åˆ°115ç½‘ç›˜
    4. å»é‡å’Œæ ‡ç­¾ç®¡ç†
    """
    
    def __init__(self, db: AsyncSession):
        self.db = db
    
    async def get_active_rules_for_chat(self, chat_id: int) -> List[ResourceMonitorRule]:
        """è·å–èŠå¤©çš„æ´»è·ƒè§„åˆ™"""
        result = await self.db.execute(
            select(ResourceMonitorRule).where(
                ResourceMonitorRule.is_active == True
            )
        )
        all_rules = result.scalars().all()
        
        # è¿‡æ»¤åŒ¹é…çš„è§„åˆ™
        matched_rules = []
        for rule in all_rules:
            source_chats = json.loads(rule.source_chats) if rule.source_chats else []
            source_chat_ids = [int(c) for c in source_chats]
            
            if int(chat_id) in source_chat_ids:
                matched_rules.append(rule)
                logger.debug(f"âœ… è§„åˆ™ '{rule.name}' åŒ¹é…èŠå¤© {chat_id}")
        
        return matched_rules
    
    async def handle_new_message(self, context: 'MessageContext'):
        """
        å¤„ç†æ–°æ¶ˆæ¯
        
        æµç¨‹ï¼š
        1. è·å–é€‚ç”¨çš„è§„åˆ™
        2. æå–é“¾æ¥
        3. å…³é”®è¯è¿‡æ»¤
        4. å»é‡æ£€æŸ¥
        5. åˆ›å»ºè®°å½•
        6. è‡ªåŠ¨è½¬å­˜ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        """
        try:
            # 1. è·å–è§„åˆ™
            rules = await self.get_active_rules_for_chat(context.chat_id)
            if not rules:
                logger.debug(f"èŠå¤© {context.chat_id} æ²¡æœ‰æ´»è·ƒçš„èµ„æºç›‘æ§è§„åˆ™")
                return
            
            logger.info(f"ğŸ“Š æ‰¾åˆ° {len(rules)} ä¸ªèµ„æºç›‘æ§è§„åˆ™")
            
            # 2. æå–é“¾æ¥
            links = await context.get_extracted_links()
            if not links:
                logger.debug("æ¶ˆæ¯ä¸­æœªæ‰¾åˆ°é“¾æ¥")
                return
            
            logger.info(f"ğŸ”— æå–åˆ°é“¾æ¥: {links}")
            
            # 3. å¤„ç†æ¯ä¸ªè§„åˆ™
            for rule in rules:
                await self._process_rule(context, rule, links)
                
        except Exception as e:
            logger.error(f"å¤„ç†æ¶ˆæ¯å¤±è´¥: {e}", exc_info=True)
    
    async def _process_rule(self, context: 'MessageContext', rule: ResourceMonitorRule, links: Dict[str, List[str]]):
        """å¤„ç†å•ä¸ªè§„åˆ™"""
        try:
            # 1. å…³é”®è¯è¿‡æ»¤
            if rule.keywords:
                keywords = json.loads(rule.keywords)
                keyword_list = [k.get('keyword', '') for k in keywords if not k.get('is_exclude', False)]
                exclude_keywords = [k.get('keyword', '') for k in keywords if k.get('is_exclude', False)]
                
                # æ£€æŸ¥æ’é™¤å…³é”®è¯
                message_text = (context.message.text or "").lower()
                for exclude_keyword in exclude_keywords:
                    if exclude_keyword.lower() in message_text:
                        logger.info(f"è§„åˆ™ {rule.name} å‘½ä¸­æ’é™¤å…³é”®è¯: {exclude_keyword}")
                        return
                
                # æ£€æŸ¥åŒ…å«å…³é”®è¯
                if keyword_list:
                    matched = await context.get_matched_keywords(keyword_list)
                    if not matched:
                        logger.info(f"è§„åˆ™ {rule.name} å…³é”®è¯ä¸åŒ¹é…")
                        return
            
            # 2. é“¾æ¥ç±»å‹è¿‡æ»¤
            link_types = json.loads(rule.link_types) if rule.link_types else []
            
            # 3. å¤„ç†æ¯ä¸ªé“¾æ¥
            for link_type in link_types:
                if link_type not in links:
                    continue
                
                for link_url in links[link_type]:
                    await self._process_link(context, rule, link_type, link_url)
                    
        except Exception as e:
            logger.error(f"å¤„ç†è§„åˆ™ {rule.name} å¤±è´¥: {e}", exc_info=True)
    
    async def _process_link(self, context: 'MessageContext', rule: ResourceMonitorRule, 
                           link_type: str, link_url: str):
        """å¤„ç†å•ä¸ªé“¾æ¥"""
        try:
            # 1. å»é‡æ£€æŸ¥
            link_hash = LinkExtractor.calculate_hash(link_url)
            
            if rule.enable_deduplication:
                if await self._is_duplicate(link_hash, rule.dedup_time_window):
                    logger.info(f"é“¾æ¥å·²å­˜åœ¨ï¼ˆå»é‡ï¼‰: {link_url[:50]}...")
                    return
            
            # 2. åˆ›å»ºè®°å½•
            record = await self._create_record(context, rule, link_type, link_url, link_hash)
            
            # 3. è‡ªåŠ¨å¤„ç†ï¼ˆç»Ÿä¸€è·¯ç”± + å˜é‡æ¸²æŸ“ + ç±»å‹ä¸“å±è·¯å¾„è¦†ç›–ï¼‰
            # è§„åˆ™å¯é€‰å­—æ®µï¼štarget_path_pan115 / target_path_magnet / target_path_ed2k
            override_path = getattr(rule, f"target_path_{link_type}", None) if hasattr(rule, f"target_path_{link_type}") else None
            if rule.auto_save_to_115 and link_type == 'pan115':
                await self._auto_save_to_115(record, rule, context, override_path)
            if link_type in ('magnet', 'ed2k'):
                await self._auto_offline_via_clouddrive2(record, rule, context, override_path)
                
        except Exception as e:
            logger.error(f"å¤„ç†é“¾æ¥å¤±è´¥: {e}", exc_info=True)
    
    async def _is_duplicate(self, link_hash: str, time_window: int) -> bool:
        """æ£€æŸ¥é“¾æ¥æ˜¯å¦é‡å¤"""
        cutoff_time = get_user_now() - timedelta(seconds=time_window)
        
        result = await self.db.execute(
            select(ResourceRecord).where(
                and_(
                    ResourceRecord.link_hash == link_hash,
                    ResourceRecord.created_at >= cutoff_time
                )
            ).limit(1)
        )
        
        return result.scalar_one_or_none() is not None
    
    async def _create_record(self, context: 'MessageContext', rule: ResourceMonitorRule,
                            link_type: str, link_url: str, link_hash: str) -> ResourceRecord:
        """åˆ›å»ºèµ„æºè®°å½•"""
        from timezone_utils import telegram_time_to_user_time
        
        # è·å–é»˜è®¤æ ‡ç­¾
        default_tags = json.loads(rule.default_tags) if rule.default_tags else []
        
        # è½¬æ¢æ¶ˆæ¯æ—¶é—´åˆ°ç”¨æˆ·æ—¶åŒº
        user_time = telegram_time_to_user_time(context.message.date)
        
        # åˆ›å»ºæ¶ˆæ¯å¿«ç…§
        message_snapshot = {
            'id': context.message.id,
            'date': user_time.isoformat() if user_time else None,
            'text': context.message.text or "",
            'chat_id': context.chat_id
        }
        
        record = ResourceRecord(
            rule_id=rule.id,
            rule_name=rule.name,
            source_chat_id=str(context.chat_id),
            message_id=context.message.id,
            message_text=context.message.text or "",
            message_date=user_time,
            link_type=link_type,
            link_url=link_url,
            link_hash=link_hash,
            save_status='pending',
            tags=json.dumps(default_tags, ensure_ascii=False),
            message_snapshot=json.dumps(message_snapshot, ensure_ascii=False)
        )
        
        self.db.add(record)
        await self.db.commit()
        await self.db.refresh(record)
        
        logger.info(f"âœ… åˆ›å»ºèµ„æºè®°å½•: ID={record.id}, ç±»å‹={link_type}, é“¾æ¥={link_url[:50]}...")
        return record
    
    def _get_cd2_api_root(self) -> str:
        """è¯»å– CloudDrive2 åœ¨çº¿æ ¹ï¼ˆä¼˜å…ˆ CLOUDDRIVE2_API_ROOTï¼Œå¦åˆ™ä» MOUNT_POINT æ¨å¯¼ï¼‰ã€‚"""
        import os
        api_root = os.getenv('CLOUDDRIVE2_API_ROOT', '').strip()
        if api_root:
            return api_root if api_root.startswith('/') else '/' + api_root
        mount_point = os.getenv('CLOUDDRIVE2_MOUNT_POINT', '').strip()
        if mount_point.startswith('/CloudNAS/'):
            return '/' + mount_point.split('/')[-1]
        return '/115open'

    def _expand_variables(self, pattern: str, context: 'MessageContext', rule: ResourceMonitorRule) -> str:
        """å±•å¼€ {YYYY}/{MM}/{DD}/{chat}/{rule} å˜é‡ã€‚"""
        try:
            now = get_user_now()
            mapping = {
                'YYYY': f"{now.year:04d}",
                'MM': f"{now.month:02d}",
                'DD': f"{now.day:02d}",
                'chat': str(context.chat_id),
                'rule': rule.name or 'rule'
            }
            out = pattern or ''
            for k, v in mapping.items():
                out = out.replace('{' + k + '}', v)
            return out
        except Exception:
            return pattern or ''

    def _normalize_relative_path(self, path: str, api_root: str) -> str:
        """è§„èŒƒä¸ºç›¸å¯¹å±‚çº§ï¼šå‰¥ç¦» /CloudNAS/<root> æˆ– api_rootã€‚"""
        p = (path or '').replace('\\', '/').strip()
        if not p:
            return ''
        if p.startswith('/'):
            if p.startswith('/CloudNAS/'):
                parts = p.split('/')
                p = '/'.join(parts[3:])
            elif api_root and p.startswith(api_root.rstrip('/') + '/'):
                p = p[len(api_root.rstrip('/')) + 1:]
            elif api_root and p == api_root:
                p = ''
            else:
                p = p.lstrip('/')
        return p.strip('/')

    def _compute_final_paths(self, raw_target_path: str, context: 'MessageContext', rule: ResourceMonitorRule) -> Dict[str, str]:
        """è¿”å› {'relative','cd2_folder','pan115_folder'}"""
        api_root = self._get_cd2_api_root()
        expanded = self._expand_variables(raw_target_path or '', context, rule)
        rel = self._normalize_relative_path(expanded, api_root)
        pan115_folder = '/' + rel if rel else '/'
        cd2_folder = (api_root.rstrip('/') + '/' + rel).rstrip('/') if rel else api_root
        return {'relative': rel, 'cd2_folder': cd2_folder, 'pan115_folder': pan115_folder}

    async def _auto_save_to_115(self, record: ResourceRecord, rule: ResourceMonitorRule, context: 'MessageContext', override_path: str | None = None):
        """è‡ªåŠ¨è½¬å­˜åˆ°115"""
        try:
            # æ›´æ–°çŠ¶æ€ä¸º"è½¬å­˜ä¸­"
            record.save_status = 'saving'
            await self.db.commit()
            
            logger.info(f"âš¡ å¼€å§‹115è½¬å­˜: record_id={record.id}")
            
            # æå–åˆ†äº«ç 
            match = re.search(r'/s/([a-zA-Z0-9]+)', record.link_url)
            if not match:
                raise ValueError("æ— æ³•æå–åˆ†äº«ç ")
            
            share_code = match.group(1)
            
            # æå–å¯†ç ï¼ˆå¦‚æœæœ‰ï¼‰
            password_match = re.search(r'password=([a-zA-Z0-9]+)', record.link_url)
            receive_code = password_match.group(1) if password_match else None
            
            logger.info(f"ğŸ“‹ è½¬å­˜å‚æ•°: share_code={share_code}, receive_code={receive_code}, target_path={rule.target_path}")
            
            # è°ƒç”¨115è½¬å­˜API
            from services.pan115_client import Pan115Client
            from models import MediaSettings
            from sqlalchemy import select
            
            # è·å–115é…ç½®
            settings_result = await self.db.execute(select(MediaSettings))
            settings = settings_result.scalars().first()
            
            if not settings:
                raise ValueError("æœªæ‰¾åˆ°115ç½‘ç›˜é…ç½®")
            
            user_id = getattr(settings, 'pan115_user_id', None)
            user_key = getattr(settings, 'pan115_user_key', None)
            
            if not user_id or not user_key:
                raise ValueError("è¯·å…ˆç™»å½•115ç½‘ç›˜")
            
            # åˆ›å»º115å®¢æˆ·ç«¯ï¼ˆä»…ä½¿ç”¨Web APIï¼‰
            client = Pan115Client(
                app_id="",  # ä½¿ç”¨Web API
                app_key="",
                user_id=user_id,
                user_key=user_key,
                use_proxy=getattr(settings, 'pan115_use_proxy', False)
            )
            
            # ç»Ÿä¸€è·¯ç”± + å˜é‡å±•å¼€ï¼ˆæ”¯æŒç±»å‹ä¸“å±è¦†ç›–ï¼‰
            raw_path = override_path if (override_path and str(override_path).strip() != '') else (rule.target_path or '/')
            routed = self._compute_final_paths(raw_path, context, rule)
            target_path = routed['pan115_folder']
            target_dir_id = "0"  # é»˜è®¤æ ¹ç›®å½•
            
            if target_path and target_path != "/":
                # åˆ›å»ºç›®å½•è·¯å¾„å¹¶è·å–ç›®å½•ID
                logger.info(f"ğŸ“ åˆ›å»ºç›®æ ‡ç›®å½•: {target_path}")
                dir_result = await client.create_directory_path(target_path)
                
                if dir_result.get('success'):
                    target_dir_id = dir_result.get('dir_id', '0')
                    logger.info(f"âœ… ç›®æ ‡ç›®å½•ID: {target_dir_id}")
                else:
                    logger.warning(f"âš ï¸ åˆ›å»ºç›®å½•å¤±è´¥ï¼Œä½¿ç”¨æ ¹ç›®å½•: {dir_result.get('message')}")
            
            # è°ƒç”¨è½¬å­˜API
            save_result = await client.save_share(
                share_code=share_code,
                receive_code=receive_code,
                target_dir_id=target_dir_id
            )
            
            if save_result.get('success'):
                saved_count = save_result.get('saved_count', 0)
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºé‡å¤
                if save_result.get('duplicate'):
                    logger.info(f"âš ï¸ 115è½¬å­˜é‡å¤: record_id={record.id}, æ–‡ä»¶å·²å­˜åœ¨")
                    record.save_status = 'duplicate'
                    record.save_path = target_path or "/"
                    record.save_time = get_user_now()
                    record.save_error = "æ–‡ä»¶å·²å­˜åœ¨ï¼ˆä¹‹å‰å·²è½¬å­˜ï¼‰"
                else:
                    logger.info(f"âœ… 115è½¬å­˜æˆåŠŸ: record_id={record.id}, è½¬å­˜äº†{saved_count}ä¸ªæ–‡ä»¶")
                    record.save_status = 'success'
                    record.save_path = target_path or "/"
                    record.save_time = get_user_now()
                
                await self.db.commit()
            else:
                error_msg = save_result.get('message', 'è½¬å­˜å¤±è´¥')
                raise ValueError(error_msg)
            
        except Exception as e:
            logger.error(f"115è½¬å­˜å¤±è´¥: {e}", exc_info=True)
            
            # æ›´æ–°å¤±è´¥çŠ¶æ€
            record.save_status = 'failed'
            record.save_error = str(e)
            record.retry_count += 1
            await self.db.commit()
            
            # åŠ å…¥é‡è¯•é˜Ÿåˆ—
            try:
                from services.common.retry_queue import get_retry_queue, RetryStrategy
                retry_queue = get_retry_queue()
                
                await retry_queue.add_task(
                    task_id=f"115_save_{record.id}",
                    task_type="resource_115_save",
                    task_data={
                        'record_id': record.id,
                        'rule_id': rule.id,
                        'share_code': share_code,
                        'receive_code': receive_code,
                        'target_path': target_path
                    },
                    max_retries=3,
                    strategy=RetryStrategy.EXPONENTIAL,
                    base_delay=300  # 5åˆ†é’Ÿ
                )
                logger.info(f"å·²åŠ å…¥é‡è¯•é˜Ÿåˆ—: record_id={record.id}")
            except Exception as retry_error:
                logger.error(f"åŠ å…¥é‡è¯•é˜Ÿåˆ—å¤±è´¥: {retry_error}")

    async def _auto_offline_via_clouddrive2(self, record: ResourceRecord, rule: ResourceMonitorRule, context: 'MessageContext', override_path: str | None = None):
        """ç£åŠ›/ed2k é€šè¿‡ CloudDrive2 æ·»åŠ ç¦»çº¿ä»»åŠ¡"""
        try:
            # ç›®æ ‡ç›®å½•ï¼šè§„åˆ™ target_path ä½œä¸ºç›¸å¯¹è·¯å¾„æ‹¼åˆ° CloudDrive2 é»˜è®¤æ ¹
            from services.clouddrive2_client import create_clouddrive2_client
            import os

            client = create_clouddrive2_client()
            await client.connect()

            # ç»Ÿä¸€è·¯ç”±ï¼ˆç»å¯¹CD2ç›®å½•ï¼‰- æ”¯æŒç±»å‹ä¸“å±è¦†ç›–
            raw_path = override_path if (override_path and str(override_path).strip() != '') else (rule.target_path or '/')
            routed = self._compute_final_paths(raw_path, context, rule)
            to_folder = routed['cd2_folder']

            # æäº¤ç¦»çº¿ä»»åŠ¡
            logger.info(f"âš¡ æäº¤ç¦»çº¿ä»»åŠ¡: url={record.link_url[:60]}..., folder={to_folder}")
            res = await client.add_offline_file(record.link_url, to_folder)
            await client.disconnect()

            if res.get('success'):
                record.save_status = 'queued'
                record.save_path = res.get('folder') or to_folder
                record.save_time = get_user_now()
                record.save_error = None
                await self.db.commit()
                logger.info(f"âœ… å·²æäº¤ç¦»çº¿ä»»åŠ¡: record_id={record.id}")
            else:
                raise ValueError(res.get('message', 'æäº¤ç¦»çº¿ä»»åŠ¡å¤±è´¥'))

        except Exception as e:
            logger.error(f"CloudDrive2 ç¦»çº¿ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
            record.save_status = 'failed'
            record.save_error = str(e)
            record.retry_count += 1
            await self.db.commit()


# åˆ›å»ºèµ„æºç›‘æ§å¤„ç†å™¨
from services.message_dispatcher import MessageProcessor

class ResourceMonitorProcessor(MessageProcessor):
    """èµ„æºç›‘æ§æ¶ˆæ¯å¤„ç†å™¨"""
    
    def __init__(self):
        """ä¸éœ€è¦ä¼ å…¥æ•°æ®åº“ä¼šè¯ï¼Œæ¯æ¬¡å¤„ç†æ—¶åŠ¨æ€è·å–"""
        pass
    
    async def should_process(self, context: 'MessageContext') -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥å¤„ç†è¿™æ¡æ¶ˆæ¯"""
        # æ¯æ¬¡å¤„ç†æ—¶è·å–æ–°çš„æ•°æ®åº“ä¼šè¯
        async for db in get_db():
            service = ResourceMonitorService(db)
            rules = await service.get_active_rules_for_chat(context.chat_id)
            return len(rules) > 0
        return False
    
    async def process(self, context: 'MessageContext') -> bool:
        """å¤„ç†æ¶ˆæ¯"""
        try:
            # æ¯æ¬¡å¤„ç†æ—¶è·å–æ–°çš„æ•°æ®åº“ä¼šè¯
            async for db in get_db():
                service = ResourceMonitorService(db)
                await service.handle_new_message(context)
                break
            return True
        except Exception as e:
            logger.error(f"ResourceMonitorProcessor å¤„ç†å¤±è´¥: {e}", exc_info=True)
            return False


# ===== é‡è¯•å¤„ç†å™¨ =====

async def handle_115_save_retry(task) -> bool:
    """å¤„ç†115è½¬å­˜é‡è¯•ä»»åŠ¡"""
    from services.common.retry_queue import RetryTask
    
    try:
        record_id = task.task_data['record_id']
        rule_id = task.task_data['rule_id']
        share_code = task.task_data['share_code']
        receive_code = task.task_data.get('receive_code')
        target_path = task.task_data.get('target_path', '/')
        
        logger.info(f"ğŸ”„ é‡è¯•115è½¬å­˜: record_id={record_id}, é‡è¯•æ¬¡æ•°={task.retry_count}")
        
        # è·å–æ•°æ®åº“ä¼šè¯
        async for db in get_db():
            # è·å–è®°å½•
            record = await db.get(ResourceRecord, record_id)
            if not record:
                logger.error(f"è®°å½•ä¸å­˜åœ¨: record_id={record_id}")
                return False
            
            # æ›´æ–°çŠ¶æ€
            record.save_status = 'saving'
            record.retry_count = task.retry_count
            await db.commit()
            
            # æå–åˆ†äº«ç å’Œå¯†ç 
            import re
            match = re.search(r'/s/([a-zA-Z0-9]+)', record.link_url)
            if not match:
                raise ValueError("æ— æ³•æå–åˆ†äº«ç ")
            
            share_code = match.group(1)
            password_match = re.search(r'password=([a-zA-Z0-9]+)', record.link_url)
            receive_code = password_match.group(1) if password_match else None
            
            # è°ƒç”¨115è½¬å­˜API
            from services.pan115_client import Pan115Client
            from models import MediaSettings
            from sqlalchemy import select
            
            # è·å–115é…ç½®
            settings_result = await db.execute(select(MediaSettings))
            settings = settings_result.scalars().first()
            
            if not settings:
                raise ValueError("æœªæ‰¾åˆ°115ç½‘ç›˜é…ç½®")
            
            user_id = getattr(settings, 'pan115_user_id', None)
            user_key = getattr(settings, 'pan115_user_key', None)
            
            if not user_id or not user_key:
                raise ValueError("è¯·å…ˆç™»å½•115ç½‘ç›˜")
            
            # åˆ›å»º115å®¢æˆ·ç«¯ï¼ˆä»…ä½¿ç”¨Web APIï¼‰
            client = Pan115Client(
                app_id="",  # ä½¿ç”¨Web API
                app_key="",
                user_id=user_id,
                user_key=user_key,
                use_proxy=getattr(settings, 'pan115_use_proxy', False)
            )
            
            # è·å–æˆ–åˆ›å»ºç›®æ ‡ç›®å½•
            target_dir_id = "0"  # é»˜è®¤æ ¹ç›®å½•
            
            if target_path and target_path != "/":
                # åˆ›å»ºç›®å½•è·¯å¾„å¹¶è·å–ç›®å½•ID
                logger.info(f"ğŸ“ é‡è¯•: åˆ›å»ºç›®æ ‡ç›®å½•: {target_path}")
                dir_result = await client.create_directory_path(target_path)
                
                if dir_result.get('success'):
                    target_dir_id = dir_result.get('dir_id', '0')
                    logger.info(f"âœ… é‡è¯•: ç›®æ ‡ç›®å½•ID: {target_dir_id}")
                else:
                    logger.warning(f"âš ï¸ é‡è¯•: åˆ›å»ºç›®å½•å¤±è´¥ï¼Œä½¿ç”¨æ ¹ç›®å½•: {dir_result.get('message')}")
            
            # è°ƒç”¨è½¬å­˜API
            save_result = await client.save_share(
                share_code=share_code,
                receive_code=receive_code,
                target_dir_id=target_dir_id
            )
            
            if save_result.get('success'):
                saved_count = save_result.get('saved_count', 0)
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºé‡å¤
                if save_result.get('duplicate'):
                    logger.info(f"âš ï¸ é‡è¯•è½¬å­˜é‡å¤: record_id={record_id}, æ–‡ä»¶å·²å­˜åœ¨")
                    record.save_status = 'duplicate'
                    record.save_path = target_path
                    record.save_time = get_user_now()
                    record.save_error = "æ–‡ä»¶å·²å­˜åœ¨ï¼ˆä¹‹å‰å·²è½¬å­˜ï¼‰"
                else:
                    logger.info(f"âœ… é‡è¯•è½¬å­˜æˆåŠŸ: record_id={record_id}, è½¬å­˜äº†{saved_count}ä¸ªæ–‡ä»¶")
                    record.save_status = 'success'
                    record.save_path = target_path
                    record.save_time = get_user_now()
                    record.save_error = None  # æ¸…ç©ºä¹‹å‰çš„é”™è¯¯ä¿¡æ¯
                
                await db.commit()
                return True
            else:
                error_msg = save_result.get('message', 'è½¬å­˜å¤±è´¥')
                logger.error(f"âŒ é‡è¯•è½¬å­˜å¤±è´¥: record_id={record_id}, {error_msg}")
                
                # æ ‡è®°ä¸ºå¤±è´¥
                record.save_status = 'failed'
                record.save_error = error_msg
                await db.commit()
                return False
    
    except Exception as e:
        logger.error(f"é‡è¯•å¤±è´¥: {e}", exc_info=True)
        return False


def register_retry_handlers():
    """æ³¨å†Œé‡è¯•å¤„ç†å™¨"""
    from services.common.retry_queue import get_retry_queue
    
    retry_queue = get_retry_queue()
    retry_queue.register_handler("resource_115_save", handle_115_save_retry)
    logger.info("âœ… æ³¨å†Œèµ„æºç›‘æ§é‡è¯•å¤„ç†å™¨")

