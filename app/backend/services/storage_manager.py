"""
å­˜å‚¨ç©ºé—´ç®¡ç†å’Œè‡ªåŠ¨æ¸…ç†æœåŠ¡
"""
import os
import asyncio
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
from sqlalchemy import select, and_
from sqlalchemy.ext.asyncio import AsyncSession

from log_manager import get_logger

logger = get_logger('storage_manager')
from database import get_db
from models import MediaFile, MediaMonitorRule


class StorageManager:
    """å­˜å‚¨ç©ºé—´ç®¡ç†å™¨"""
    
    def __init__(self):
        self.cleanup_task = None
        self.is_running = False
    
    async def start(self, check_interval: int = 3600):
        """
        å¯åŠ¨å­˜å‚¨ç®¡ç†æœåŠ¡
        
        Args:
            check_interval: æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤1å°æ—¶
        """
        if self.is_running:
            logger.warning("å­˜å‚¨ç®¡ç†æœåŠ¡å·²åœ¨è¿è¡Œ")
            return
        
        self.is_running = True
        logger.info("ğŸ’¾ å¯åŠ¨å­˜å‚¨ç©ºé—´ç®¡ç†æœåŠ¡")
        
        # å¯åŠ¨å®šæ—¶æ¸…ç†ä»»åŠ¡
        self.cleanup_task = asyncio.create_task(self._cleanup_loop(check_interval))
    
    async def stop(self):
        """åœæ­¢å­˜å‚¨ç®¡ç†æœåŠ¡"""
        if not self.is_running:
            return
        
        self.is_running = False
        logger.info("ğŸ›‘ åœæ­¢å­˜å‚¨ç©ºé—´ç®¡ç†æœåŠ¡")
        
        if self.cleanup_task:
            self.cleanup_task.cancel()
            try:
                await self.cleanup_task
            except asyncio.CancelledError:
                pass
    
    async def _cleanup_loop(self, interval: int):
        """å®šæ—¶æ¸…ç†å¾ªç¯"""
        logger.info(f"ğŸ”„ å­˜å‚¨æ¸…ç†å¾ªç¯å·²å¯åŠ¨ï¼ˆé—´éš”: {interval}ç§’ï¼‰")
        
        while self.is_running:
            try:
                # ç­‰å¾…é—´éš”æ—¶é—´
                await asyncio.sleep(interval)
                
                if not self.is_running:
                    break
                
                # æ‰§è¡Œè‡ªåŠ¨æ¸…ç†
                logger.info("ğŸ§¹ å¼€å§‹è‡ªåŠ¨å­˜å‚¨æ¸…ç†...")
                
                async for db in get_db():
                    # è·å–æ‰€æœ‰å¯ç”¨è‡ªåŠ¨æ¸…ç†çš„è§„åˆ™
                    result = await db.execute(
                        select(MediaMonitorRule).where(
                            and_(
                                MediaMonitorRule.is_active == True,
                                MediaMonitorRule.auto_cleanup_enabled == True
                            )
                        )
                    )
                    rules = result.scalars().all()
                    
                    for rule in rules:
                        await self._cleanup_for_rule(db, rule)
                    
                    break
                
                logger.info("âœ… è‡ªåŠ¨å­˜å‚¨æ¸…ç†å®Œæˆ")
                
            except asyncio.CancelledError:
                logger.info("æ¸…ç†å¾ªç¯è¢«å–æ¶ˆ")
                break
            except Exception as e:
                logger.error(f"è‡ªåŠ¨æ¸…ç†å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
    
    async def _cleanup_for_rule(self, db: AsyncSession, rule: MediaMonitorRule):
        """
        ä¸ºå•ä¸ªè§„åˆ™æ‰§è¡Œæ¸…ç†
        
        Args:
            db: æ•°æ®åº“ä¼šè¯
            rule: ç›‘æ§è§„åˆ™
        """
        try:
            logger.info(f"ğŸ§¹ æ¸…ç†è§„åˆ™: {rule.name} (ID: {rule.id})")
            
            # è®¡ç®—æˆªæ­¢æ—¥æœŸ
            cutoff_date = datetime.now() - timedelta(days=rule.auto_cleanup_days or 7)
            
            # æŸ¥è¯¢éœ€è¦æ¸…ç†çš„æ–‡ä»¶
            query = select(MediaFile).where(
                and_(
                    MediaFile.monitor_rule_id == rule.id,
                    MediaFile.downloaded_at < cutoff_date
                )
            )
            
            # å¦‚æœåªæ¸…ç†å·²å½’æ¡£çš„æ–‡ä»¶
            if rule.cleanup_only_organized:
                query = query.where(MediaFile.is_organized == True)
            
            result = await db.execute(query)
            files_to_cleanup = result.scalars().all()
            
            if not files_to_cleanup:
                logger.info(f"  æ— éœ€æ¸…ç†çš„æ–‡ä»¶")
                return
            
            cleaned_count = 0
            cleaned_size_mb = 0
            
            for file in files_to_cleanup:
                try:
                    # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                    if file.temp_path and os.path.exists(file.temp_path):
                        file_size = os.path.getsize(file.temp_path)
                        os.remove(file.temp_path)
                        cleaned_size_mb += file_size / (1024 * 1024)
                        cleaned_count += 1
                        logger.debug(f"  ğŸ—‘ï¸ åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {file.temp_path}")
                    
                    # å¦‚æœæ–‡ä»¶å·²ä¸Šä¼ åˆ°äº‘ç«¯ï¼Œä¹Ÿå¯ä»¥åˆ é™¤å½’æ¡£æ–‡ä»¶
                    if file.is_uploaded_to_cloud and file.final_path and os.path.exists(file.final_path):
                        file_size = os.path.getsize(file.final_path)
                        os.remove(file.final_path)
                        cleaned_size_mb += file_size / (1024 * 1024)
                        logger.debug(f"  â˜ï¸ åˆ é™¤å·²ä¸Šä¼ æ–‡ä»¶: {file.final_path}")
                    
                    # æ›´æ–°æ•°æ®åº“è®°å½•ï¼ˆä¿ç•™è®°å½•ä½†æ¸…ç©ºè·¯å¾„ï¼‰
                    if file.temp_path and not os.path.exists(file.temp_path):
                        file.temp_path = None
                    if file.final_path and not os.path.exists(file.final_path):
                        file.final_path = None
                    
                except Exception as e:
                    logger.warning(f"  æ¸…ç†æ–‡ä»¶å¤±è´¥: {file.file_name}, {e}")
            
            await db.commit()
            
            logger.info(f"  âœ… æ¸…ç†å®Œæˆ: {cleaned_count} ä¸ªæ–‡ä»¶, {cleaned_size_mb:.2f} MB")
            
        except Exception as e:
            logger.error(f"è§„åˆ™æ¸…ç†å¤±è´¥: {rule.name}, {e}")
            import traceback
            traceback.print_exc()
    
    async def manual_cleanup(
        self,
        rule_id: int,
        days: int,
        only_organized: bool = True,
        delete_db_records: bool = False
    ) -> Dict[str, Any]:
        """
        æ‰‹åŠ¨æ¸…ç†
        
        Args:
            rule_id: è§„åˆ™ID
            days: ä¿ç•™å¤©æ•°
            only_organized: æ˜¯å¦åªæ¸…ç†å·²å½’æ¡£æ–‡ä»¶
            delete_db_records: æ˜¯å¦åˆ é™¤æ•°æ®åº“è®°å½•
            
        Returns:
            æ¸…ç†ç»“æœ
        """
        try:
            async for db in get_db():
                # è·å–è§„åˆ™
                result = await db.execute(
                    select(MediaMonitorRule).where(MediaMonitorRule.id == rule_id)
                )
                rule = result.scalar_one_or_none()
                
                if not rule:
                    return {
                        'success': False,
                        'message': 'è§„åˆ™ä¸å­˜åœ¨'
                    }
                
                # è®¡ç®—æˆªæ­¢æ—¥æœŸ
                cutoff_date = datetime.now() - timedelta(days=days)
                
                # æŸ¥è¯¢éœ€è¦æ¸…ç†çš„æ–‡ä»¶
                query = select(MediaFile).where(
                    and_(
                        MediaFile.monitor_rule_id == rule_id,
                        MediaFile.downloaded_at < cutoff_date
                    )
                )
                
                if only_organized:
                    query = query.where(MediaFile.is_organized == True)
                
                result = await db.execute(query)
                files_to_cleanup = result.scalars().all()
                
                cleaned_files = []
                cleaned_count = 0
                cleaned_size_mb = 0
                
                for file in files_to_cleanup:
                    try:
                        file_info = {
                            'name': file.file_name,
                            'size_mb': file.file_size_mb,
                            'paths_deleted': []
                        }
                        
                        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                        if file.temp_path and os.path.exists(file.temp_path):
                            os.remove(file.temp_path)
                            file_info['paths_deleted'].append(file.temp_path)
                            cleaned_size_mb += file.file_size_mb or 0
                            cleaned_count += 1
                        
                        # åˆ é™¤å½’æ¡£æ–‡ä»¶ï¼ˆå¦‚æœå·²ä¸Šä¼ åˆ°äº‘ç«¯ï¼‰
                        if file.is_uploaded_to_cloud and file.final_path and os.path.exists(file.final_path):
                            os.remove(file.final_path)
                            file_info['paths_deleted'].append(file.final_path)
                        
                        cleaned_files.append(file_info)
                        
                        # å¦‚æœè¦åˆ é™¤æ•°æ®åº“è®°å½•
                        if delete_db_records:
                            await db.delete(file)
                        else:
                            # åªæ¸…ç©ºè·¯å¾„
                            file.temp_path = None
                            if file.is_uploaded_to_cloud:
                                file.final_path = None
                        
                    except Exception as e:
                        logger.warning(f"æ¸…ç†æ–‡ä»¶å¤±è´¥: {file.file_name}, {e}")
                
                await db.commit()
                
                logger.info(f"ğŸ§¹ æ‰‹åŠ¨æ¸…ç†å®Œæˆ: {rule.name}, {cleaned_count} ä¸ªæ–‡ä»¶, {cleaned_size_mb:.2f} MB")
                
                return {
                    'success': True,
                    'message': 'æ¸…ç†æˆåŠŸ',
                    'cleaned_count': cleaned_count,
                    'cleaned_size_mb': round(cleaned_size_mb, 2),
                    'files': cleaned_files
                }
                
        except Exception as e:
            logger.error(f"æ‰‹åŠ¨æ¸…ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return {
                'success': False,
                'message': f'æ¸…ç†å¤±è´¥: {str(e)}'
            }
    
    async def get_storage_usage(self, rule_id: Optional[int] = None) -> Dict[str, Any]:
        """
        è·å–å­˜å‚¨ä½¿ç”¨æƒ…å†µ
        
        Args:
            rule_id: è§„åˆ™IDï¼ˆå¯é€‰ï¼Œä¸æŒ‡å®šåˆ™è¿”å›æ‰€æœ‰ï¼‰
            
        Returns:
            å­˜å‚¨ä½¿ç”¨æƒ…å†µ
        """
        try:
            async for db in get_db():
                if rule_id:
                    # å•ä¸ªè§„åˆ™çš„ä½¿ç”¨æƒ…å†µ
                    result = await db.execute(
                        select(MediaMonitorRule).where(MediaMonitorRule.id == rule_id)
                    )
                    rule = result.scalar_one_or_none()
                    
                    if not rule:
                        return {
                            'success': False,
                            'message': 'è§„åˆ™ä¸å­˜åœ¨'
                        }
                    
                    temp_size, organized_size = await self._calculate_folder_sizes(rule)
                    
                    return {
                        'success': True,
                        'rule_id': rule_id,
                        'rule_name': rule.name,
                        'temp_size_gb': round(temp_size / (1024**3), 2),
                        'organized_size_gb': round(organized_size / (1024**3), 2),
                        'total_size_gb': round((temp_size + organized_size) / (1024**3), 2),
                        'max_size_gb': rule.max_storage_gb,
                        'usage_percent': round((temp_size + organized_size) / (rule.max_storage_gb * 1024**3) * 100, 2) if rule.max_storage_gb else 0,
                        'total_downloaded': rule.total_downloaded or 0,
                        'total_size_mb': rule.total_size_mb or 0
                    }
                
                else:
                    # æ‰€æœ‰è§„åˆ™çš„ä½¿ç”¨æƒ…å†µ
                    result = await db.execute(select(MediaMonitorRule))
                    rules = result.scalars().all()
                    
                    total_temp = 0
                    total_organized = 0
                    rules_usage = []
                    
                    for rule in rules:
                        temp_size, organized_size = await self._calculate_folder_sizes(rule)
                        total_temp += temp_size
                        total_organized += organized_size
                        
                        rules_usage.append({
                            'rule_id': rule.id,
                            'rule_name': rule.name,
                            'temp_size_gb': round(temp_size / (1024**3), 2),
                            'organized_size_gb': round(organized_size / (1024**3), 2),
                            'total_size_gb': round((temp_size + organized_size) / (1024**3), 2)
                        })
                    
                    return {
                        'success': True,
                        'total_temp_size_gb': round(total_temp / (1024**3), 2),
                        'total_organized_size_gb': round(total_organized / (1024**3), 2),
                        'total_size_gb': round((total_temp + total_organized) / (1024**3), 2),
                        'rules': rules_usage
                    }
                
        except Exception as e:
            logger.error(f"è·å–å­˜å‚¨ä½¿ç”¨æƒ…å†µå¤±è´¥: {e}")
            return {
                'success': False,
                'message': f'è·å–å¤±è´¥: {str(e)}'
            }
    
    async def _calculate_folder_sizes(self, rule: MediaMonitorRule) -> tuple:
        """
        è®¡ç®—æ–‡ä»¶å¤¹å¤§å°
        
        Returns:
            (ä¸´æ—¶æ–‡ä»¶å¤¹å¤§å°, å½’æ¡£æ–‡ä»¶å¤¹å¤§å°) å•ä½ï¼šå­—èŠ‚
        """
        temp_size = 0
        organized_size = 0
        
        try:
            # è®¡ç®—ä¸´æ—¶æ–‡ä»¶å¤¹å¤§å°
            temp_folder = Path(rule.temp_folder or '/app/media/downloads')
            if temp_folder.exists():
                temp_size = sum(f.stat().st_size for f in temp_folder.rglob('*') if f.is_file())
            
            # è®¡ç®—å½’æ¡£æ–‡ä»¶å¤¹å¤§å°
            if rule.organize_enabled:
                if rule.organize_target_type == 'local' and rule.organize_local_path:
                    organized_folder = Path(rule.organize_local_path)
                    if organized_folder.exists():
                        organized_size = sum(f.stat().st_size for f in organized_folder.rglob('*') if f.is_file())
                
                elif rule.organize_target_type == 'clouddrive_mount' and rule.organize_clouddrive_mount:
                    mount_folder = Path(rule.organize_clouddrive_mount)
                    if mount_folder.exists():
                        organized_size = sum(f.stat().st_size for f in mount_folder.rglob('*') if f.is_file())
        
        except Exception as e:
            logger.warning(f"è®¡ç®—æ–‡ä»¶å¤¹å¤§å°å¤±è´¥: {e}")
        
        return temp_size, organized_size
    
    async def check_and_cleanup_if_needed(self, rule_id: int) -> Dict[str, Any]:
        """
        æ£€æŸ¥å­˜å‚¨ä½¿ç”¨æƒ…å†µï¼Œå¦‚æœè¶…è¿‡é˜ˆå€¼åˆ™è‡ªåŠ¨æ¸…ç†
        
        Args:
            rule_id: è§„åˆ™ID
            
        Returns:
            æ£€æŸ¥å’Œæ¸…ç†ç»“æœ
        """
        try:
            usage = await self.get_storage_usage(rule_id)
            
            if not usage.get('success'):
                return usage
            
            usage_percent = usage.get('usage_percent', 0)
            max_size_gb = usage.get('max_size_gb', 100)
            
            # å¦‚æœä½¿ç”¨ç‡è¶…è¿‡ 90%ï¼Œè§¦å‘æ¸…ç†
            if usage_percent >= 90:
                logger.warning(f"âš ï¸ å­˜å‚¨ä½¿ç”¨ç‡è¿‡é«˜: {usage_percent:.1f}%ï¼Œå¼€å§‹è‡ªåŠ¨æ¸…ç†...")
                
                # å…ˆæ¸…ç†å·²å½’æ¡£çš„ä¸´æ—¶æ–‡ä»¶ï¼ˆä¿ç•™3å¤©å†…çš„ï¼‰
                cleanup_result = await self.manual_cleanup(
                    rule_id=rule_id,
                    days=3,
                    only_organized=True,
                    delete_db_records=False
                )
                
                # é‡æ–°æ£€æŸ¥ä½¿ç”¨ç‡
                new_usage = await self.get_storage_usage(rule_id)
                new_usage_percent = new_usage.get('usage_percent', 0)
                
                if new_usage_percent >= 95:
                    # è¿˜æ˜¯ä¸å¤Ÿï¼Œæš‚åœä¸‹è½½é˜Ÿåˆ—
                    logger.error(f"ğŸš¨ å­˜å‚¨ç©ºé—´ä¸¥é‡ä¸è¶³: {new_usage_percent:.1f}%ï¼Œå»ºè®®æš‚åœä¸‹è½½æˆ–å¢åŠ å­˜å‚¨é…é¢")
                    
                    return {
                        'success': True,
                        'action': 'critical',
                        'message': 'å­˜å‚¨ç©ºé—´ä¸¥é‡ä¸è¶³ï¼Œå»ºè®®æš‚åœä¸‹è½½',
                        'usage_percent': new_usage_percent,
                        'cleaned': cleanup_result
                    }
                
                return {
                    'success': True,
                    'action': 'cleaned',
                    'message': 'å·²è‡ªåŠ¨æ¸…ç†å­˜å‚¨ç©ºé—´',
                    'usage_percent': new_usage_percent,
                    'cleaned': cleanup_result
                }
            
            return {
                'success': True,
                'action': 'none',
                'message': 'å­˜å‚¨ç©ºé—´å……è¶³',
                'usage_percent': usage_percent
            }
            
        except Exception as e:
            logger.error(f"å­˜å‚¨æ£€æŸ¥å¤±è´¥: {e}")
            return {
                'success': False,
                'message': f'æ£€æŸ¥å¤±è´¥: {str(e)}'
            }


# å…¨å±€å­˜å‚¨ç®¡ç†å™¨å®ä¾‹
_storage_manager = None


def get_storage_manager() -> StorageManager:
    """è·å–å­˜å‚¨ç®¡ç†å™¨å•ä¾‹"""
    global _storage_manager
    
    if _storage_manager is None:
        _storage_manager = StorageManager()
    
    return _storage_manager

