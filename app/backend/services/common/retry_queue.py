"""
æ™ºèƒ½é‡è¯•é˜Ÿåˆ—

åŠŸèƒ½ï¼š
1. å¤±è´¥ä»»åŠ¡è‡ªåŠ¨é‡è¯•
2. æŒ‡æ•°é€€é¿ç­–ç•¥
3. æœ€å¤§é‡è¯•æ¬¡æ•°é™åˆ¶
4. ä¼˜å…ˆçº§æ”¯æŒ
5. ç£ç›˜æŒä¹…åŒ–ï¼ˆé˜²æ­¢æ•°æ®ä¸¢å¤±ï¼‰
"""
from typing import Dict, Any, Optional, Callable, Awaitable, List
from dataclasses import dataclass, field, asdict
from datetime import datetime, timedelta
from enum import Enum
import asyncio
import heapq
import json
import os
from pathlib import Path
from log_manager import get_logger

logger = get_logger("retry_queue", "enhanced_bot.log")


class RetryStrategy(str, Enum):
    """é‡è¯•ç­–ç•¥"""
    IMMEDIATE = "immediate"  # ç«‹å³é‡è¯•
    LINEAR = "linear"  # çº¿æ€§é€€é¿ï¼ˆå›ºå®šå»¶è¿Ÿï¼‰
    EXPONENTIAL = "exponential"  # æŒ‡æ•°é€€é¿
    FIBONACCI = "fibonacci"  # æ–æ³¢é‚£å¥‘é€€é¿


@dataclass(order=True)
class RetryTask:
    """é‡è¯•ä»»åŠ¡"""
    # ä»»åŠ¡æ•°æ®ï¼ˆå¿…é¡»çš„å­—æ®µï¼‰
    task_id: str = field(compare=False)
    task_type: str = field(compare=False)
    
    # ç”¨äºä¼˜å…ˆçº§é˜Ÿåˆ—æ’åºçš„å­—æ®µ
    next_retry_time: datetime = field(compare=True)
    priority: int = field(compare=True, default=5)
    
    # ä»»åŠ¡æ•°æ®ï¼ˆå¯é€‰ï¼‰
    task_data: Dict[str, Any] = field(compare=False, default_factory=dict)
    
    # é‡è¯•ä¿¡æ¯
    retry_count: int = field(compare=False, default=0)
    max_retries: int = field(compare=False, default=3)
    strategy: RetryStrategy = field(compare=False, default=RetryStrategy.EXPONENTIAL)
    base_delay: int = field(compare=False, default=60)  # åŸºç¡€å»¶è¿Ÿï¼ˆç§’ï¼‰
    
    # é”™è¯¯ä¿¡æ¯
    last_error: Optional[str] = field(compare=False, default=None)
    error_history: list = field(compare=False, default_factory=list)
    
    # æ—¶é—´æˆ³
    created_at: datetime = field(compare=False, default_factory=datetime.now)
    last_retry_at: Optional[datetime] = field(compare=False, default=None)
    
    def calculate_next_delay(self) -> int:
        """è®¡ç®—ä¸‹æ¬¡é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰"""
        if self.strategy == RetryStrategy.IMMEDIATE:
            return 0
        
        elif self.strategy == RetryStrategy.LINEAR:
            return self.base_delay
        
        elif self.strategy == RetryStrategy.EXPONENTIAL:
            # æŒ‡æ•°é€€é¿: base_delay * 2^retry_count
            return self.base_delay * (2 ** self.retry_count)
        
        elif self.strategy == RetryStrategy.FIBONACCI:
            # æ–æ³¢é‚£å¥‘é€€é¿
            fib_sequence = [1, 1, 2, 3, 5, 8, 13, 21, 34, 55]
            index = min(self.retry_count, len(fib_sequence) - 1)
            return self.base_delay * fib_sequence[index]
        
        return self.base_delay
    
    def should_retry(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥é‡è¯•"""
        return self.retry_count < self.max_retries
    
    def record_error(self, error: str):
        """è®°å½•é”™è¯¯"""
        self.last_error = error
        self.error_history.append({
            'error': error,
            'time': datetime.now().isoformat(),
            'retry_count': self.retry_count
        })
    
    def to_dict(self) -> Dict[str, Any]:
        """åºåˆ—åŒ–ä¸ºå­—å…¸"""
        return {
            'task_id': self.task_id,
            'task_type': self.task_type,
            'task_data': self.task_data,
            'priority': self.priority,
            'retry_count': self.retry_count,
            'max_retries': self.max_retries,
            'strategy': self.strategy.value,
            'base_delay': self.base_delay,
            'next_retry_time': self.next_retry_time.isoformat(),
            'last_error': self.last_error,
            'error_history': self.error_history,
            'created_at': self.created_at.isoformat(),
            'last_retry_at': self.last_retry_at.isoformat() if self.last_retry_at else None
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'RetryTask':
        """ä»å­—å…¸ååºåˆ—åŒ–"""
        return cls(
            task_id=data['task_id'],
            task_type=data['task_type'],
            task_data=data['task_data'],
            priority=data['priority'],
            retry_count=data['retry_count'],
            max_retries=data['max_retries'],
            strategy=RetryStrategy(data['strategy']),
            base_delay=data['base_delay'],
            next_retry_time=datetime.fromisoformat(data['next_retry_time']),
            last_error=data.get('last_error'),
            error_history=data.get('error_history', []),
            created_at=datetime.fromisoformat(data['created_at']),
            last_retry_at=datetime.fromisoformat(data['last_retry_at']) if data.get('last_retry_at') else None
        )


class SmartRetryQueue:
    """
    æ™ºèƒ½é‡è¯•é˜Ÿåˆ—
    
    ç‰¹æ€§ï¼š
    1. ä¼˜å…ˆçº§é˜Ÿåˆ—
    2. å¤šç§é‡è¯•ç­–ç•¥
    3. è‡ªåŠ¨è°ƒåº¦
    4. ç»Ÿè®¡ç›‘æ§
    """
    
    def __init__(
        self,
        max_concurrent: int = 5,
        check_interval: int = 10,  # æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
        persistence_enabled: bool = True,
        persistence_path: str = "data/retry_queue.json",
        persistence_interval: int = 60  # æŒä¹…åŒ–é—´éš”ï¼ˆç§’ï¼‰
    ):
        self.max_concurrent = max_concurrent
        self.check_interval = check_interval
        self.persistence_enabled = persistence_enabled
        self.persistence_path = persistence_path
        self.persistence_interval = persistence_interval
        
        # ä¼˜å…ˆçº§é˜Ÿåˆ—ï¼ˆæœ€å°å †ï¼‰
        self._queue: List[RetryTask] = []
        self._lock = asyncio.Lock()
        
        # ä»»åŠ¡å¤„ç†å™¨æ³¨å†Œè¡¨
        self._handlers: Dict[str, Callable[[RetryTask], Awaitable[bool]]] = {}
        
        # è¿è¡ŒçŠ¶æ€
        self._is_running = False
        self._worker_tasks: List[asyncio.Task] = []
        self._scheduler_task: Optional[asyncio.Task] = None
        self._persistence_task: Optional[asyncio.Task] = None
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_added': 0,
            'total_retried': 0,
            'total_success': 0,
            'total_failed': 0,
            'total_abandoned': 0,
            'current_queue_size': 0,
            'last_persistence': None,
            'persistence_errors': 0
        }
    
    def register_handler(
        self,
        task_type: str,
        handler: Callable[[RetryTask], Awaitable[bool]]
    ):
        """
        æ³¨å†Œä»»åŠ¡å¤„ç†å™¨
        
        handler åº”è¯¥è¿”å› Trueï¼ˆæˆåŠŸï¼‰æˆ– Falseï¼ˆå¤±è´¥ï¼‰
        """
        self._handlers[task_type] = handler
        logger.info(f"âœ… æ³¨å†Œé‡è¯•å¤„ç†å™¨: {task_type}")
    
    async def start(self):
        """å¯åŠ¨é‡è¯•é˜Ÿåˆ—"""
        if self._is_running:
            return
        
        self._is_running = True
        
        # ä»ç£ç›˜åŠ è½½é˜Ÿåˆ—
        if self.persistence_enabled:
            await self._load_from_disk()
        
        # å¯åŠ¨è°ƒåº¦å™¨
        self._scheduler_task = asyncio.create_task(self._scheduler_loop())
        
        # å¯åŠ¨å·¥ä½œçº¿ç¨‹
        for i in range(self.max_concurrent):
            task = asyncio.create_task(self._worker_loop(i))
            self._worker_tasks.append(task)
        
        # å¯åŠ¨æŒä¹…åŒ–ä»»åŠ¡
        if self.persistence_enabled:
            self._persistence_task = asyncio.create_task(self._persistence_loop())
        
        logger.info(
            f"âœ… æ™ºèƒ½é‡è¯•é˜Ÿåˆ—å·²å¯åŠ¨ (workers={self.max_concurrent}, "
            f"persistence={'enabled' if self.persistence_enabled else 'disabled'})"
        )
    
    async def stop(self):
        """åœæ­¢é‡è¯•é˜Ÿåˆ—"""
        self._is_running = False
        
        # ä¿å­˜é˜Ÿåˆ—åˆ°ç£ç›˜
        if self.persistence_enabled:
            await self._save_to_disk()
        
        # åœæ­¢æŒä¹…åŒ–ä»»åŠ¡
        if self._persistence_task:
            self._persistence_task.cancel()
            try:
                await self._persistence_task
            except asyncio.CancelledError:
                pass
        
        # åœæ­¢è°ƒåº¦å™¨
        if self._scheduler_task:
            self._scheduler_task.cancel()
            try:
                await self._scheduler_task
            except asyncio.CancelledError:
                pass
        
        # åœæ­¢å·¥ä½œçº¿ç¨‹
        for task in self._worker_tasks:
            task.cancel()
        
        await asyncio.gather(*self._worker_tasks, return_exceptions=True)
        self._worker_tasks.clear()
        
        logger.info("âœ… æ™ºèƒ½é‡è¯•é˜Ÿåˆ—å·²åœæ­¢")
    
    async def add_task(
        self,
        task_id: str,
        task_type: str,
        task_data: Dict[str, Any],
        priority: int = 5,
        max_retries: int = 3,
        strategy: RetryStrategy = RetryStrategy.EXPONENTIAL,
        base_delay: int = 60
    ):
        """æ·»åŠ é‡è¯•ä»»åŠ¡"""
        async with self._lock:
            task = RetryTask(
                task_id=task_id,
                task_type=task_type,
                task_data=task_data,
                priority=priority,
                max_retries=max_retries,
                strategy=strategy,
                base_delay=base_delay,
                next_retry_time=datetime.now()  # ç«‹å³å¯é‡è¯•
            )
            
            heapq.heappush(self._queue, task)
            self.stats['total_added'] += 1
            self.stats['current_queue_size'] = len(self._queue)
            
            logger.info(f"æ·»åŠ é‡è¯•ä»»åŠ¡: {task_id} (type={task_type}, priority={priority})")
    
    async def _scheduler_loop(self):
        """è°ƒåº¦å™¨å¾ªç¯"""
        while self._is_running:
            try:
                await asyncio.sleep(self.check_interval)
                await self._check_ready_tasks()
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"è°ƒåº¦å™¨é”™è¯¯: {e}", exc_info=True)
    
    async def _check_ready_tasks(self):
        """æ£€æŸ¥å‡†å¤‡å¥½çš„ä»»åŠ¡"""
        async with self._lock:
            now = datetime.now()
            ready_count = 0
            
            # ç»Ÿè®¡å‡†å¤‡å¥½çš„ä»»åŠ¡æ•°é‡
            for task in self._queue:
                if task.next_retry_time <= now:
                    ready_count += 1
            
            if ready_count > 0:
                logger.debug(f"å‘ç° {ready_count} ä¸ªå‡†å¤‡å¥½çš„é‡è¯•ä»»åŠ¡")
    
    async def _worker_loop(self, worker_id: int):
        """å·¥ä½œçº¿ç¨‹å¾ªç¯"""
        logger.info(f"ğŸ‘· é‡è¯•å·¥ä½œçº¿ç¨‹ #{worker_id+1} å·²å¯åŠ¨")
        
        while self._is_running:
            try:
                # è·å–ä¸‹ä¸€ä¸ªå‡†å¤‡å¥½çš„ä»»åŠ¡
                task = await self._get_next_ready_task()
                
                if task is None:
                    # æ²¡æœ‰å‡†å¤‡å¥½çš„ä»»åŠ¡ï¼Œç­‰å¾…
                    await asyncio.sleep(1)
                    continue
                
                # å¤„ç†ä»»åŠ¡
                await self._process_task(task, worker_id)
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"[Worker #{worker_id+1}] å¤„ç†ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
    
    async def _get_next_ready_task(self) -> Optional[RetryTask]:
        """è·å–ä¸‹ä¸€ä¸ªå‡†å¤‡å¥½çš„ä»»åŠ¡"""
        async with self._lock:
            now = datetime.now()
            
            # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªå‡†å¤‡å¥½çš„ä»»åŠ¡
            if self._queue and self._queue[0].next_retry_time <= now:
                task = heapq.heappop(self._queue)
                self.stats['current_queue_size'] = len(self._queue)
                return task
            
            return None
    
    async def _process_task(self, task: RetryTask, worker_id: int):
        """å¤„ç†ä»»åŠ¡"""
        logger.info(f"[Worker #{worker_id+1}] é‡è¯•ä»»åŠ¡: {task.task_id} (ç¬¬ {task.retry_count + 1} æ¬¡)")
        
        # è·å–å¤„ç†å™¨
        handler = self._handlers.get(task.task_type)
        if handler is None:
            logger.error(f"æœªæ‰¾åˆ°ä»»åŠ¡ç±»å‹ {task.task_type} çš„å¤„ç†å™¨")
            self.stats['total_failed'] += 1
            return
        
        # æ‰§è¡Œå¤„ç†å™¨
        try:
            success = await handler(task)
            
            if success:
                # æˆåŠŸ
                logger.info(f"[Worker #{worker_id+1}] ä»»åŠ¡æˆåŠŸ: {task.task_id}")
                self.stats['total_success'] += 1
                self.stats['total_retried'] += 1
            else:
                # å¤±è´¥ï¼Œé‡æ–°åŠ å…¥é˜Ÿåˆ—
                await self._handle_task_failure(task, "å¤„ç†å™¨è¿”å›å¤±è´¥")
        
        except Exception as e:
            # å¼‚å¸¸ï¼Œé‡æ–°åŠ å…¥é˜Ÿåˆ—
            error_msg = f"å¤„ç†å™¨å¼‚å¸¸: {str(e)}"
            logger.error(f"[Worker #{worker_id+1}] {error_msg}", exc_info=True)
            await self._handle_task_failure(task, error_msg)
    
    async def _handle_task_failure(self, task: RetryTask, error: str):
        """å¤„ç†ä»»åŠ¡å¤±è´¥"""
        task.retry_count += 1
        task.last_retry_at = datetime.now()
        task.record_error(error)
        
        if task.should_retry():
            # è®¡ç®—ä¸‹æ¬¡é‡è¯•æ—¶é—´
            delay = task.calculate_next_delay()
            task.next_retry_time = datetime.now() + timedelta(seconds=delay)
            
            # é‡æ–°åŠ å…¥é˜Ÿåˆ—
            async with self._lock:
                heapq.heappush(self._queue, task)
                self.stats['current_queue_size'] = len(self._queue)
            
            logger.warning(
                f"ä»»åŠ¡å¤±è´¥ï¼Œå°†åœ¨ {delay}ç§’ åé‡è¯•: {task.task_id} "
                f"(é‡è¯•æ¬¡æ•°: {task.retry_count}/{task.max_retries})"
            )
        else:
            # æ”¾å¼ƒé‡è¯•
            logger.error(
                f"ä»»åŠ¡å·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ”¾å¼ƒ: {task.task_id} "
                f"(é‡è¯•æ¬¡æ•°: {task.retry_count}/{task.max_retries})"
            )
            self.stats['total_abandoned'] += 1
            self.stats['total_failed'] += 1
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'current_queue_size': self.stats['current_queue_size'],
            'total_added': self.stats['total_added'],
            'total_retried': self.stats['total_retried'],
            'total_success': self.stats['total_success'],
            'total_failed': self.stats['total_failed'],
            'total_abandoned': self.stats['total_abandoned'],
            'success_rate': (
                f"{(self.stats['total_success'] / self.stats['total_retried'] * 100):.2f}%"
                if self.stats['total_retried'] > 0 else "0.00%"
            )
        }
    
    async def get_queue_status(self) -> Dict[str, int]:
        """è·å–é˜Ÿåˆ—ä¸­å„ä»»åŠ¡ç±»å‹çš„æ•°é‡"""
        async with self._lock:
            task_types: Dict[str, int] = {}
            for task in self._queue:
                task_type = task.task_type
                task_types[task_type] = task_types.get(task_type, 0) + 1
            return task_types
    
    # ===== æŒä¹…åŒ–ç›¸å…³æ–¹æ³• =====
    
    async def _persistence_loop(self):
        """å®šæœŸæŒä¹…åŒ–å¾ªç¯"""
        while self._is_running:
            try:
                await asyncio.sleep(self.persistence_interval)
                await self._save_to_disk()
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"æŒä¹…åŒ–å¾ªç¯é”™è¯¯: {e}", exc_info=True)
                self.stats['persistence_errors'] += 1
    
    async def _save_to_disk(self):
        """ä¿å­˜é˜Ÿåˆ—åˆ°ç£ç›˜"""
        try:
            async with self._lock:
                # åºåˆ—åŒ–é˜Ÿåˆ—
                queue_data = {
                    'version': '1.0',
                    'saved_at': datetime.now().isoformat(),
                    'tasks': [task.to_dict() for task in self._queue],
                    'stats': self.stats.copy()
                }
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            path = Path(self.persistence_path)
            path.parent.mkdir(parents=True, exist_ok=True)
            
            # å†™å…¥ä¸´æ—¶æ–‡ä»¶
            temp_path = f"{self.persistence_path}.tmp"
            with open(temp_path, 'w', encoding='utf-8') as f:
                json.dump(queue_data, f, indent=2, ensure_ascii=False)
            
            # åŸå­æ€§æ›¿æ¢
            os.replace(temp_path, self.persistence_path)
            
            self.stats['last_persistence'] = datetime.now().isoformat()
            logger.debug(f"é˜Ÿåˆ—å·²ä¿å­˜åˆ°ç£ç›˜: {len(queue_data['tasks'])} ä¸ªä»»åŠ¡")
        
        except Exception as e:
            logger.error(f"ä¿å­˜é˜Ÿåˆ—åˆ°ç£ç›˜å¤±è´¥: {e}", exc_info=True)
            self.stats['persistence_errors'] += 1
    
    async def _load_from_disk(self):
        """ä»ç£ç›˜åŠ è½½é˜Ÿåˆ—"""
        try:
            path = Path(self.persistence_path)
            if not path.exists():
                logger.info("æœªæ‰¾åˆ°æŒä¹…åŒ–æ–‡ä»¶ï¼Œä»ç©ºé˜Ÿåˆ—å¼€å§‹")
                return
            
            # è¯»å–æ–‡ä»¶
            with open(path, 'r', encoding='utf-8') as f:
                queue_data = json.load(f)
            
            # éªŒè¯ç‰ˆæœ¬
            version = queue_data.get('version', '1.0')
            if version != '1.0':
                logger.warning(f"æŒä¹…åŒ–æ–‡ä»¶ç‰ˆæœ¬ä¸åŒ¹é…: {version}, è·³è¿‡åŠ è½½")
                return
            
            # æ¢å¤ä»»åŠ¡
            tasks = queue_data.get('tasks', [])
            loaded_count = 0
            
            async with self._lock:
                for task_data in tasks:
                    try:
                        task = RetryTask.from_dict(task_data)
                        heapq.heappush(self._queue, task)
                        loaded_count += 1
                    except Exception as e:
                        logger.error(f"æ¢å¤ä»»åŠ¡å¤±è´¥: {e}")
                        continue
                
                self.stats['current_queue_size'] = len(self._queue)
            
            logger.info(
                f"âœ… ä»ç£ç›˜åŠ è½½é˜Ÿåˆ—: {loaded_count}/{len(tasks)} ä¸ªä»»åŠ¡, "
                f"ä¿å­˜æ—¶é—´: {queue_data.get('saved_at', 'unknown')}"
            )
        
        except Exception as e:
            logger.error(f"ä»ç£ç›˜åŠ è½½é˜Ÿåˆ—å¤±è´¥: {e}", exc_info=True)
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œå…è®¸ä»ç©ºé˜Ÿåˆ—å¼€å§‹


# å…¨å±€é‡è¯•é˜Ÿåˆ—å®ä¾‹
_retry_queue: Optional[SmartRetryQueue] = None


def get_retry_queue() -> SmartRetryQueue:
    """è·å–å…¨å±€é‡è¯•é˜Ÿåˆ—å®ä¾‹"""
    global _retry_queue
    if _retry_queue is None:
        _retry_queue = SmartRetryQueue()
        logger.info("âœ… åˆ›å»ºå…¨å±€æ™ºèƒ½é‡è¯•é˜Ÿåˆ—")
    return _retry_queue


async def init_retry_queue():
    """åˆå§‹åŒ–æ™ºèƒ½é‡è¯•é˜Ÿåˆ—"""
    queue = get_retry_queue()
    await queue.start()
    return queue

