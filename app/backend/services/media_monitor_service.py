"""
åª’ä½“ç›‘æ§æœåŠ¡
è´Ÿè´£ç›‘å¬ Telegram æ¶ˆæ¯ï¼Œä¸‹è½½ç¬¦åˆè§„åˆ™çš„åª’ä½“æ–‡ä»¶
"""
import asyncio
import json
import hashlib
import shutil
import os
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, List, Any
from sqlalchemy import select, or_
from sqlalchemy.ext.asyncio import AsyncSession

from log_manager import get_logger

logger = get_logger('media_monitor')
from database import get_db
from models import MediaMonitorRule, DownloadTask, MediaFile, MediaSettings
from utils.media_filters import MediaFilter
from utils.message_deduplicator import SenderFilter
from utils.media_metadata import MediaMetadataExtractor

# å¯¼å…¥ 115ç½‘ç›˜ Open API å®¢æˆ·ç«¯
try:
    from services.pan115_client import Pan115Client
    PAN115_AVAILABLE = True
except ImportError:
    PAN115_AVAILABLE = False
    logger.warning("115ç½‘ç›˜å®¢æˆ·ç«¯æœªå®‰è£…ï¼Œ115ç›´ä¼ åŠŸèƒ½å°†ä¸å¯ç”¨")


class FileOrganizer:
    """æ–‡ä»¶å½’æ¡£ç®¡ç†å™¨"""
    
    @staticmethod
    def generate_target_directory(rule: MediaMonitorRule, metadata: Dict[str, Any]) -> str:
        """
        ç”Ÿæˆç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„
        
        Args:
            rule: ç›‘æ§è§„åˆ™
            metadata: å…ƒæ•°æ®ï¼ˆåŒ…å«å‘é€è€…ã€æ¥æºç­‰ä¿¡æ¯ï¼‰
            
        Returns:
            ç›¸å¯¹è·¯å¾„å­—ç¬¦ä¸²
        """
        from datetime import datetime
        
        if rule.folder_structure == 'flat':
            return ''
        
        elif rule.folder_structure == 'date':
            now = datetime.now()
            return f"{now.year}/{now.month:02d}/{now.day:02d}"
        
        elif rule.folder_structure == 'type':
            file_type = metadata.get('type', 'other')
            return file_type
        
        elif rule.folder_structure == 'source':
            source = metadata.get('source_chat', 'unknown')
            return FileOrganizer._sanitize_path(source)
        
        elif rule.folder_structure == 'sender':
            # ä¼˜å…ˆä½¿ç”¨ sender_nameï¼ˆåŒ…å«ç”¨æˆ·åæˆ–çœŸå®å§“åï¼‰ï¼Œfallback åˆ° sender_usernameï¼Œæœ€åæ˜¯ sender_id
            sender = metadata.get('sender_name') or metadata.get('sender_username') or str(metadata.get('sender_id', 'unknown'))
            return FileOrganizer._sanitize_path(sender)
        
        elif rule.folder_structure == 'custom':
            template = rule.custom_folder_template or '{type}/{year}/{month}/{day}'
            now = datetime.now()
            
            replacements = {
                '{year}': str(now.year),
                '{month}': f"{now.month:02d}",
                '{day}': f"{now.day:02d}",
                '{type}': metadata.get('type', 'other'),
                '{source}': FileOrganizer._sanitize_path(metadata.get('source_chat', 'unknown')),
                '{source_id}': metadata.get('source_chat_id', 'unknown'),
                '{sender}': FileOrganizer._sanitize_path(
                    metadata.get('sender_name') or metadata.get('sender_username') or str(metadata.get('sender_id', 'unknown'))
                ),
                '{sender_id}': str(metadata.get('sender_id', 'unknown')),
            }
            
            path = template
            for key, value in replacements.items():
                path = path.replace(key, value)
            
            return path
        
        return ''
    
    @staticmethod
    def generate_filename(rule: MediaMonitorRule, original_name: str, metadata: Dict[str, Any]) -> str:
        """
        ç”Ÿæˆç›®æ ‡æ–‡ä»¶å
        
        Args:
            rule: ç›‘æ§è§„åˆ™
            original_name: åŸå§‹æ–‡ä»¶å
            metadata: å…ƒæ•°æ®
            
        Returns:
            æ–‡ä»¶åå­—ç¬¦ä¸²
        """
        if not rule.rename_files or not rule.filename_template:
            return original_name
        
        template = rule.filename_template
        now = datetime.now()
        
        # åˆ†ç¦»æ‰©å±•å
        name_without_ext = Path(original_name).stem
        extension = Path(original_name).suffix
        
        replacements = {
            '{date}': now.strftime('%Y%m%d'),
            '{time}': now.strftime('%H%M%S'),
            '{sender}': FileOrganizer._sanitize_filename(
                metadata.get('sender_name') or metadata.get('sender_username') or str(metadata.get('sender_id', 'unknown'))
            ),
            '{source}': FileOrganizer._sanitize_filename(metadata.get('source_chat', 'unknown')),
            '{type}': metadata.get('type', 'file'),
            '{original_name}': name_without_ext
        }
        
        filename = template
        for key, value in replacements.items():
            filename = filename.replace(key, str(value))
        
        return filename + extension
    
    @staticmethod
    async def organize_file(
        rule: MediaMonitorRule,
        temp_path: str,
        metadata: Dict[str, Any]
    ) -> Optional[str]:
        """
        å½’æ¡£æ–‡ä»¶
        
        Args:
            rule: ç›‘æ§è§„åˆ™
            temp_path: ä¸´æ—¶æ–‡ä»¶è·¯å¾„
            metadata: å…ƒæ•°æ®
            
        Returns:
            å½’æ¡£åçš„æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å› None
        """
        try:
            if not rule.organize_enabled:
                return None
            
            # ç”Ÿæˆç›®æ ‡è·¯å¾„
            target_dir_relative = FileOrganizer.generate_target_directory(rule, metadata)
            original_filename = Path(temp_path).name
            target_filename = FileOrganizer.generate_filename(rule, original_filename, metadata)
            
            # æ ¹æ®å½’æ¡£ç›®æ ‡ç±»å‹ç¡®å®šåŸºç¡€è·¯å¾„
            base_path = Path(rule.organize_local_path or '/app/media/organized')
            
            # å®Œæ•´ç›®æ ‡è·¯å¾„
            target_dir = base_path / target_dir_relative
            target_dir.mkdir(parents=True, exist_ok=True)
            
            target_path = target_dir / target_filename
            
            # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œæ·»åŠ åºå·
            counter = 1
            while target_path.exists():
                name_without_ext = Path(target_filename).stem
                extension = Path(target_filename).suffix
                target_path = target_dir / f"{name_without_ext}_{counter}{extension}"
                counter += 1
            
            # æ‰§è¡Œå½’æ¡£
            if rule.organize_mode == 'move':
                shutil.move(temp_path, target_path)
                logger.info(f"ğŸ“¦ ç§»åŠ¨æ–‡ä»¶: {temp_path} -> {target_path}")
            else:  # copy
                shutil.copy2(temp_path, target_path)
                logger.info(f"ğŸ“‹ å¤åˆ¶æ–‡ä»¶: {temp_path} -> {target_path}")
                
                # å¦‚æœä¸ä¿ç•™ä¸´æ—¶æ–‡ä»¶ï¼Œåˆ é™¤å®ƒ
                if not rule.keep_temp_file:
                    os.remove(temp_path)
                    logger.info(f"ğŸ—‘ï¸ åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {temp_path}")
            
            return str(target_path)
            
        except Exception as e:
            logger.error(f"æ–‡ä»¶å½’æ¡£å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    @staticmethod
    def _sanitize_path(path: str) -> str:
        """æ¸…ç†è·¯å¾„å­—ç¬¦ä¸²ï¼Œç§»é™¤éæ³•å­—ç¬¦"""
        # ç§»é™¤è·¯å¾„ä¸­çš„éæ³•å­—ç¬¦
        illegal_chars = ['<', '>', ':', '"', '|', '?', '*']
        for char in illegal_chars:
            path = path.replace(char, '_')
        return path.strip()
    
    @staticmethod
    def _sanitize_filename(filename: str) -> str:
        """æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤éæ³•å­—ç¬¦"""
        # ç§»é™¤æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦
        illegal_chars = ['/', '\\', '<', '>', ':', '"', '|', '?', '*']
        for char in illegal_chars:
            filename = filename.replace(char, '_')
        return filename.strip()


class MediaMonitorService:
    """åª’ä½“ç›‘æ§æœåŠ¡"""
    
    def __init__(self):
        self.active_monitors: Dict[int, bool] = {}  # rule_id -> is_active
        self.download_queue = asyncio.Queue()
        self.download_workers: List[asyncio.Task] = []
        self.is_running = False
        self.global_settings: Optional[MediaSettings] = None
        
    def _get_config_value(self, key: str, default: Any = None) -> Any:
        """è·å–é…ç½®å€¼ï¼ˆä¼˜å…ˆä½¿ç”¨å…¨å±€é…ç½®ï¼‰"""
        if self.global_settings and hasattr(self.global_settings, key):
            value = getattr(self.global_settings, key)
            return value if value is not None else default
        return default
    
    async def _load_global_settings(self):
        """åŠ è½½å…¨å±€åª’ä½“é…ç½®"""
        try:
            async for db in get_db():
                result = await db.execute(select(MediaSettings))
                settings = result.scalars().first()
                
                if settings:
                    self.global_settings = settings
                    logger.info("âœ… å·²åŠ è½½å…¨å±€åª’ä½“é…ç½®")
                else:
                    # åˆ›å»ºé»˜è®¤é…ç½®
                    settings = MediaSettings(
                        temp_folder="/app/media/downloads",
                        concurrent_downloads=3,
                        retry_on_failure=True,
                        max_retries=3,
                        extract_metadata=True,
                        metadata_mode="lightweight",
                        metadata_timeout=10,
                        async_metadata_extraction=True,
                        auto_cleanup_enabled=True,
                        auto_cleanup_days=7,
                        cleanup_only_organized=True,
                        max_storage_gb=100
                    )
                    db.add(settings)
                    await db.commit()
                    await db.refresh(settings)
                    self.global_settings = settings
                    logger.info("ğŸ“ åˆ›å»ºé»˜è®¤å…¨å±€åª’ä½“é…ç½®")
                break
        except Exception as e:
            logger.error(f"åŠ è½½å…¨å±€é…ç½®å¤±è´¥: {e}")
            # ä½¿ç”¨å†…å­˜ä¸­çš„é»˜è®¤é…ç½®
            self.global_settings = None
    
    async def start(self):
        """å¯åŠ¨ç›‘æ§æœåŠ¡"""
        if self.is_running:
            logger.warning("åª’ä½“ç›‘æ§æœåŠ¡å·²åœ¨è¿è¡Œ")
            return
        
        self.is_running = True
        logger.info("ğŸ¬ å¯åŠ¨åª’ä½“ç›‘æ§æœåŠ¡")
        
        # é‡ç½®æ‰€æœ‰"ä¸‹è½½ä¸­"çš„ä»»åŠ¡çŠ¶æ€ï¼ˆå®¹å™¨é‡å¯åè¿™äº›ä»»åŠ¡å·²ä¸­æ–­ï¼‰
        await self._reset_downloading_tasks()
        
        # åŠ è½½å…¨å±€é…ç½®
        await self._load_global_settings()
        
        # å¯åŠ¨ä¸‹è½½å·¥ä½œçº¿ç¨‹
        await self._start_download_workers()
        
        # åŠ è½½å¹¶å¯åŠ¨æ‰€æœ‰æ´»è·ƒçš„ç›‘æ§è§„åˆ™
        await self._load_active_rules()
    
    async def _reset_downloading_tasks(self):
        """é‡ç½®æ‰€æœ‰"ä¸‹è½½ä¸­"çŠ¶æ€çš„ä»»åŠ¡ï¼ˆå®¹å™¨é‡å¯åéœ€è¦è°ƒç”¨ï¼‰"""
        try:
            async for db in get_db():
                # æŸ¥æ‰¾æ‰€æœ‰"ä¸‹è½½ä¸­"ã€"ç­‰å¾…ä¸­"æˆ–"å¤±è´¥"çŠ¶æ€çš„ä»»åŠ¡ï¼ˆå¤±è´¥çš„ä¹Ÿå¯ä»¥è‡ªåŠ¨é‡è¯•ï¼‰
                result = await db.execute(
                    select(DownloadTask).where(
                        or_(
                            DownloadTask.status == 'downloading',
                            DownloadTask.status == 'pending',
                            DownloadTask.status == 'failed'
                        )
                    )
                )
                interrupted_tasks = result.scalars().all()
                
                if interrupted_tasks:
                    logger.info(f"ğŸ”„ å‘ç° {len(interrupted_tasks)} ä¸ªä¸­æ–­çš„ä¸‹è½½ä»»åŠ¡ï¼Œå‡†å¤‡è‡ªåŠ¨ç»­ä¼ ")
                    
                    # å°†ä»»åŠ¡æŒ‰è§„åˆ™åˆ†ç»„ï¼Œå‡†å¤‡é‡æ–°åŠ å…¥é˜Ÿåˆ—
                    tasks_by_rule = {}
                    for task in interrupted_tasks:
                        if task.monitor_rule_id not in tasks_by_rule:
                            tasks_by_rule[task.monitor_rule_id] = []
                        tasks_by_rule[task.monitor_rule_id].append(task)
                    
                    # å¯¹æ¯ä¸ªä»»åŠ¡å°è¯•è‡ªåŠ¨ç»­ä¼ 
                    resumed_count = 0
                    failed_count = 0
                    
                    for rule_id, tasks in tasks_by_rule.items():
                        # è·å–è§„åˆ™
                        rule_result = await db.execute(
                            select(MediaMonitorRule).where(MediaMonitorRule.id == rule_id)
                        )
                        rule = rule_result.scalar_one_or_none()
                        
                        if not rule:
                            logger.warning(f"è§„åˆ™ä¸å­˜åœ¨: {rule_id}ï¼Œæ— æ³•ç»­ä¼ ç›¸å…³ä»»åŠ¡")
                            for task in tasks:
                                task.status = 'failed'
                                task.failed_at = datetime.now()
                                task.last_error = "å…³è”çš„ç›‘æ§è§„åˆ™å·²åˆ é™¤"
                                failed_count += 1
                            continue
                        
                        # ä¸ºæ¯ä¸ªä»»åŠ¡å°è¯•ç»­ä¼ 
                        for task in tasks:
                            # æ£€æŸ¥é‡è¯•æ¬¡æ•°ï¼Œé¿å…æ— é™é‡è¯•
                            max_auto_retry = task.max_retries or 3
                            current_retry = task.retry_count or 0
                            
                            if current_retry >= max_auto_retry:
                                logger.warning(f"   - è·³è¿‡ä»»åŠ¡ï¼ˆå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•° {max_auto_retry}ï¼‰: {task.file_name} (ID: {task.id})")
                                task.status = 'failed'
                                task.last_error = f"å·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆ{max_auto_retry}æ¬¡ï¼‰ï¼Œè¯·æ‰‹åŠ¨é‡è¯•"
                                failed_count += 1
                                continue
                            
                            # é‡ç½®ä¸ºpendingçŠ¶æ€ï¼Œä¿ç•™è¿›åº¦ä¿¡æ¯
                            old_status = task.status
                            task.status = 'pending'
                            task.retry_count = current_retry + 1
                            task.last_error = f"å®¹å™¨é‡å¯è‡ªåŠ¨é‡è¯•ä¸­... (ç¬¬{task.retry_count}/{max_auto_retry}æ¬¡)"
                            
                            logger.info(f"   - å‡†å¤‡ç»­ä¼ : {task.file_name} (ID: {task.id}, åŸçŠ¶æ€: {old_status}, é‡è¯•: {task.retry_count}/{max_auto_retry})")
                            resumed_count += 1
                    
                    await db.commit()
                    
                    logger.info(f"âœ… ä»»åŠ¡é‡ç½®å®Œæˆ: {resumed_count}ä¸ªå¾…ç»­ä¼ , {failed_count}ä¸ªå¤±è´¥")
                    logger.info(f"ğŸ’¡ æç¤º: ç³»ç»Ÿå°†åœ¨5ç§’åè‡ªåŠ¨å°è¯•ç»­ä¼ è¿™äº›ä»»åŠ¡")
                    
                    # å»¶è¿Ÿ5ç§’åå¯åŠ¨è‡ªåŠ¨ç»­ä¼ 
                    import asyncio
                    asyncio.create_task(self._auto_resume_tasks(db))
                else:
                    logger.info("âœ… æ²¡æœ‰éœ€è¦é‡ç½®çš„ä¸‹è½½ä»»åŠ¡")
                
                break  # åªéœ€è¦æ‰§è¡Œä¸€æ¬¡
        except Exception as e:
            logger.error(f"é‡ç½®ä¸‹è½½ä»»åŠ¡å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    async def _auto_resume_tasks(self, db: AsyncSession):
        """è‡ªåŠ¨ç»­ä¼ ä¸­æ–­çš„ä»»åŠ¡"""
        try:
            # ç­‰å¾…5ç§’ï¼Œç¡®ä¿æ‰€æœ‰æœåŠ¡éƒ½å·²å¯åŠ¨
            await asyncio.sleep(5)
            
            logger.info("ğŸš€ å¼€å§‹è‡ªåŠ¨ç»­ä¼ ä¸­æ–­çš„ä¸‹è½½ä»»åŠ¡...")
            
            # æŸ¥æ‰¾æ‰€æœ‰pendingçŠ¶æ€çš„ä»»åŠ¡
            result = await db.execute(
                select(DownloadTask).where(DownloadTask.status == 'pending')
            )
            pending_tasks = result.scalars().all()
            
            if not pending_tasks:
                logger.info("æ²¡æœ‰å¾…ç»­ä¼ çš„ä»»åŠ¡")
                return
            
            # è·å–enhanced_botå®ä¾‹
            from main import get_enhanced_bot
            enhanced_bot = get_enhanced_bot()
            if not enhanced_bot:
                logger.error("æ— æ³•è·å–enhanced_botå®ä¾‹ï¼Œç»­ä¼ å¤±è´¥")
                return
            
            # ä¸ºæ¯ä¸ªä»»åŠ¡é‡æ–°è·å–æ¶ˆæ¯å¹¶åŠ å…¥é˜Ÿåˆ—
            resumed = 0
            failed = 0
            
            for task in pending_tasks:
                try:
                    # æŸ¥æ‰¾å¯ç”¨çš„å®¢æˆ·ç«¯
                    client_wrapper = None
                    client = None
                    
                    for client_manager in enhanced_bot.multi_client_manager.clients.values():
                        if client_manager.is_authorized and client_manager.loop and client_manager.client:
                            client_wrapper = client_manager
                            client = client_manager.client
                            break
                    
                    if not client or not client_wrapper:
                        raise Exception("æ²¡æœ‰å¯ç”¨çš„Telegramå®¢æˆ·ç«¯")
                    
                    # é‡æ–°è·å–æ¶ˆæ¯
                    if not task.chat_id or not task.message_id:
                        raise Exception("ä»»åŠ¡ç¼ºå°‘chat_idæˆ–message_id")
                    
                    future = asyncio.run_coroutine_threadsafe(
                        client.get_messages(int(task.chat_id), message_ids=task.message_id),
                        client_wrapper.loop
                    )
                    message = future.result(timeout=10)
                    
                    if not message:
                        raise Exception("æ— æ³•è·å–åŸå§‹æ¶ˆæ¯")
                    
                    # åŠ å…¥ä¸‹è½½é˜Ÿåˆ—
                    await self.download_queue.put({
                        'task_id': task.id,
                        'rule_id': task.monitor_rule_id,
                        'message_id': task.message_id,
                        'chat_id': int(task.chat_id),
                        'file_name': task.file_name,
                        'file_type': task.file_type,
                        'client': client,
                        'message': message,
                        'client_wrapper': client_wrapper
                    })
                    
                    logger.info(f"âœ… ç»­ä¼ ä»»åŠ¡å·²åŠ å…¥é˜Ÿåˆ—: {task.file_name}")
                    resumed += 1
                    
                except Exception as e:
                    logger.error(f"âŒ ç»­ä¼ ä»»åŠ¡å¤±è´¥ {task.file_name}: {e}")
                    task.status = 'failed'
                    task.failed_at = datetime.now()
                    task.last_error = f"è‡ªåŠ¨ç»­ä¼ å¤±è´¥: {str(e)}"
                    failed += 1
            
            await db.commit()
            logger.info(f"ğŸ‰ è‡ªåŠ¨ç»­ä¼ å®Œæˆ: {resumed}ä¸ªæˆåŠŸ, {failed}ä¸ªå¤±è´¥")
            
        except Exception as e:
            logger.error(f"è‡ªåŠ¨ç»­ä¼ ä»»åŠ¡å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
    
    async def stop(self):
        """åœæ­¢ç›‘æ§æœåŠ¡"""
        if not self.is_running:
            return
        
        self.is_running = False
        logger.info("ğŸ›‘ åœæ­¢åª’ä½“ç›‘æ§æœåŠ¡")
        
        # åœæ­¢æ‰€æœ‰ä¸‹è½½å·¥ä½œçº¿ç¨‹
        for worker in self.download_workers:
            worker.cancel()
        
        self.download_workers.clear()
        self.active_monitors.clear()
    
    async def _load_active_rules(self):
        """åŠ è½½æ‰€æœ‰æ´»è·ƒçš„ç›‘æ§è§„åˆ™"""
        try:
            async for db in get_db():
                result = await db.execute(
                    select(MediaMonitorRule).where(MediaMonitorRule.is_active == True)
                )
                active_rules = result.scalars().all()
                
                for rule in active_rules:
                    self.active_monitors[rule.id] = True
                    logger.info(f"âœ… åŠ è½½ç›‘æ§è§„åˆ™: {rule.name} (ID: {rule.id})")
                
                logger.info(f"ğŸ“Š å·²åŠ è½½ {len(active_rules)} ä¸ªæ´»è·ƒç›‘æ§è§„åˆ™")
                break
                
        except Exception as e:
            logger.error(f"åŠ è½½ç›‘æ§è§„åˆ™å¤±è´¥: {e}")
    
    async def _start_download_workers(self, worker_count: int = 5):
        """å¯åŠ¨ä¸‹è½½å·¥ä½œçº¿ç¨‹ï¼ˆå¢åŠ å¹¶å‘æå‡é€Ÿåº¦ï¼‰"""
        for i in range(worker_count):
            worker = asyncio.create_task(self._download_worker(i))
            self.download_workers.append(worker)
            logger.info(f"ğŸ”§ å¯åŠ¨ä¸‹è½½å·¥ä½œçº¿ç¨‹ #{i+1}")
    
    async def _download_worker(self, worker_id: int):
        """ä¸‹è½½å·¥ä½œçº¿ç¨‹"""
        logger.info(f"ğŸ‘· ä¸‹è½½å·¥ä½œçº¿ç¨‹ #{worker_id+1} å·²å¯åŠ¨")
        
        while self.is_running:
            try:
                # ä»é˜Ÿåˆ—è·å–ä¸‹è½½ä»»åŠ¡
                task = await asyncio.wait_for(
                    self.download_queue.get(),
                    timeout=1.0
                )
                
                logger.info(f"[Worker #{worker_id+1}] å¼€å§‹ä¸‹è½½: {task['file_name']}")
                
                # æ‰§è¡Œä¸‹è½½
                await self._execute_download(task)
                
                # æ ‡è®°ä»»åŠ¡å®Œæˆ
                self.download_queue.task_done()
                
            except asyncio.TimeoutError:
                # é˜Ÿåˆ—ä¸ºç©ºï¼Œç»§ç»­ç­‰å¾…
                continue
            except Exception as e:
                logger.error(f"[Worker #{worker_id+1}] ä¸‹è½½ä»»åŠ¡å¤±è´¥: {e}")
    
    async def process_message(self, client, message, rule_id: int, client_wrapper=None):
        """
        å¤„ç†æ¥æ”¶åˆ°çš„æ¶ˆæ¯
        
        Args:
            client: Telegram å®¢æˆ·ç«¯
            message: æ¶ˆæ¯å¯¹è±¡
            rule_id: ç›‘æ§è§„åˆ™ID
            client_wrapper: å®¢æˆ·ç«¯åŒ…è£…å™¨ï¼ˆç”¨äºè®¿é—®äº‹ä»¶å¾ªç¯ï¼‰
        """
        try:
            logger.info(f"ğŸ” å¤„ç†åª’ä½“æ¶ˆæ¯: rule_id={rule_id}, message_id={message.id}")
            logger.info(f"ğŸ“Š å½“å‰æ´»è·ƒç›‘æ§è§„åˆ™: {list(self.active_monitors.keys())}")
            
            # æ£€æŸ¥è§„åˆ™æ˜¯å¦æ´»è·ƒ
            if rule_id not in self.active_monitors:
                logger.warning(f"âš ï¸ è§„åˆ™ {rule_id} ä¸åœ¨æ´»è·ƒç›‘æ§åˆ—è¡¨ä¸­ï¼Œè·³è¿‡å¤„ç†")
                return
            
            # è·å–è§„åˆ™é…ç½®
            async for db in get_db():
                result = await db.execute(
                    select(MediaMonitorRule).where(MediaMonitorRule.id == rule_id)
                )
                rule = result.scalar_one_or_none()
                
                if not rule or not rule.is_active:
                    logger.warning(f"âš ï¸ è§„åˆ™ {rule_id} æœªæ‰¾åˆ°æˆ–æœªæ¿€æ´»")
                    return
                
                # æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦åŒ…å«åª’ä½“
                if not self._has_media(message):
                    logger.info(f"â­ï¸ æ¶ˆæ¯ {message.id} ä¸åŒ…å«åª’ä½“ï¼Œè·³è¿‡")
                    return
                
                logger.info(f"âœ… æ¶ˆæ¯ {message.id} åŒ…å«åª’ä½“ï¼Œåº”ç”¨è¿‡æ»¤å™¨")
                
                # åº”ç”¨è¿‡æ»¤å™¨
                if not await self._apply_filters(message, rule):
                    logger.info(f"â­ï¸ æ¶ˆæ¯ {message.id} æœªé€šè¿‡è¿‡æ»¤å™¨")
                    return
                
                logger.info(f"âœ… æ¶ˆæ¯ {message.id} é€šè¿‡æ‰€æœ‰è¿‡æ»¤å™¨ï¼Œåˆ›å»ºä¸‹è½½ä»»åŠ¡")
                
                # åˆ›å»ºä¸‹è½½ä»»åŠ¡ï¼ˆä¼ é€’client_wrapperï¼‰
                await self._create_download_task(db, message, rule, client, client_wrapper)
                
                break
                
        except Exception as e:
            logger.error(f"å¤„ç†æ¶ˆæ¯å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    def _has_media(self, message) -> bool:
        """æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦åŒ…å«åª’ä½“"""
        return bool(
            message.photo or
            message.video or
            message.audio or
            message.voice or
            message.document
        )
    
    async def _apply_filters(self, message, rule: MediaMonitorRule) -> bool:
        """
        åº”ç”¨æ‰€æœ‰è¿‡æ»¤å™¨
        
        Returns:
            æ˜¯å¦é€šè¿‡æ‰€æœ‰è¿‡æ»¤å™¨
        """
        try:
            # 1. æ–‡ä»¶ç±»å‹è¿‡æ»¤
            if rule.media_types:
                media_types_raw = rule.media_types
                # å¦‚æœå·²ç»æ˜¯åˆ—è¡¨ï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦åˆ™è§£æJSON
                if isinstance(media_types_raw, str):
                    allowed_types = json.loads(media_types_raw)
                    # å¦‚æœè§£æç»“æœä»æ˜¯å­—ç¬¦ä¸²ï¼ˆåŒé‡ç¼–ç ï¼‰ï¼Œå†è§£æä¸€æ¬¡
                    if isinstance(allowed_types, str):
                        allowed_types = json.loads(allowed_types)
                else:
                    allowed_types = media_types_raw
                
                if not MediaFilter.check_file_type(message, allowed_types):
                    logger.info(f"â­ï¸ æ–‡ä»¶ç±»å‹ä¸åŒ¹é…ï¼Œè·³è¿‡ã€‚å…è®¸çš„ç±»å‹: {allowed_types}")
                    return False
            
            # 2. æ–‡ä»¶å¤§å°è¿‡æ»¤
            if not MediaFilter.check_file_size(message, rule.min_size_mb or 0, rule.max_size_mb or 2000):
                logger.info(f"â­ï¸ æ–‡ä»¶å¤§å°ä¸ç¬¦åˆè¦æ±‚ï¼Œè·³è¿‡ã€‚èŒƒå›´: {rule.min_size_mb}-{rule.max_size_mb} MB")
                return False
            
            # 3. æ–‡ä»¶åè¿‡æ»¤
            if not MediaFilter.check_filename(message, rule.filename_include, rule.filename_exclude):
                logger.info(f"â­ï¸ æ–‡ä»¶åä¸åŒ¹é…ï¼Œè·³è¿‡ã€‚åŒ…å«: {rule.filename_include}, æ’é™¤: {rule.filename_exclude}")
                return False
            
            # 4. æ–‡ä»¶æ‰©å±•åè¿‡æ»¤
            if rule.file_extensions:
                extensions_raw = rule.file_extensions
                # å¦‚æœå·²ç»æ˜¯åˆ—è¡¨ï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦åˆ™è§£æJSON
                if isinstance(extensions_raw, str):
                    allowed_extensions = json.loads(extensions_raw)
                    # å¦‚æœè§£æç»“æœä»æ˜¯å­—ç¬¦ä¸²ï¼ˆåŒé‡ç¼–ç ï¼‰ï¼Œå†è§£æä¸€æ¬¡
                    if isinstance(allowed_extensions, str):
                        allowed_extensions = json.loads(allowed_extensions)
                else:
                    allowed_extensions = extensions_raw
                
                if allowed_extensions and not MediaFilter.check_file_extension(message, allowed_extensions):
                    logger.info(f"â­ï¸ æ–‡ä»¶æ‰©å±•åä¸åŒ¹é…ï¼Œè·³è¿‡ã€‚å…è®¸çš„æ‰©å±•å: {allowed_extensions}")
                    return False
            
            # 5. å‘é€è€…è¿‡æ»¤
            if rule.enable_sender_filter:
                sender_info = SenderFilter.get_sender_info(message)
                is_allowed = SenderFilter.is_sender_allowed(
                    sender_info['id'],
                    sender_info['username'],
                    rule.sender_filter_mode or 'whitelist',
                    rule.sender_whitelist,
                    rule.sender_blacklist
                )
                
                if not is_allowed:
                    logger.info(f"â­ï¸ å‘é€è€…è¢«è¿‡æ»¤ï¼Œè·³è¿‡: {sender_info['username'] or sender_info['id']}")
                    return False
            
            return True
            
        except Exception as e:
            logger.error(f"åº”ç”¨è¿‡æ»¤å™¨å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    async def _create_download_task(
        self,
        db: AsyncSession,
        message,
        rule: MediaMonitorRule,
        client,
        client_wrapper=None
    ):
        """åˆ›å»ºä¸‹è½½ä»»åŠ¡"""
        try:
            # è·å–åª’ä½“ä¿¡æ¯
            media_info = MediaFilter.get_media_info(message)
            
            # ç”Ÿæˆæ–‡ä»¶åï¼ˆç¡®ä¿æœ‰æ‰©å±•åï¼‰
            if media_info['filename']:
                filename = media_info['filename']
            else:
                # æ ¹æ®åª’ä½“ç±»å‹ç”Ÿæˆé»˜è®¤æ–‡ä»¶å
                ext = media_info['extension'] or ''
                if not ext and media_info['type']:
                    # å¦‚æœæ²¡æœ‰æ‰©å±•åï¼Œæ ¹æ®ç±»å‹æ¨æ–­
                    type_ext_map = {
                        'photo': '.jpg',
                        'video': '.mp4',
                        'document': '.file',
                        'audio': '.mp3',
                        'voice': '.ogg',
                        'sticker': '.webp'
                    }
                    ext = type_ext_map.get(media_info['type'], '.file')
                filename = f"{media_info['type']}_{message.id}{ext}"
            
            # æå–æ–‡ä»¶å…ƒæ•°æ®ï¼ˆç”¨äºé‡æ–°ä¸‹è½½ï¼‰
            file_unique_id = None
            file_access_hash = None
            media_json = None
            
            try:
                import json
                if hasattr(message, 'media') and message.media:
                    # è·å–æ–‡ä»¶çš„å”¯ä¸€IDå’Œè®¿é—®å“ˆå¸Œ
                    if hasattr(message.media, 'document'):
                        doc = message.media.document
                        if hasattr(doc, 'id'):
                            file_unique_id = str(doc.id)
                        if hasattr(doc, 'access_hash'):
                            file_access_hash = str(doc.access_hash)
                    elif hasattr(message.media, 'photo'):
                        photo = message.media.photo
                        if hasattr(photo, 'id'):
                            file_unique_id = str(photo.id)
                        if hasattr(photo, 'access_hash'):
                            file_access_hash = str(photo.access_hash)
                    
                    # ä¿å­˜åª’ä½“ä¿¡æ¯JSONï¼ˆç”¨äºæ¢å¤ï¼‰
                    media_dict = {
                        'type': media_info['type'],
                        'filename': filename,
                        'size': media_info['size'],
                        'mime_type': media_info.get('mime_type')
                    }
                    media_json = json.dumps(media_dict, ensure_ascii=False)
            except Exception as e:
                logger.warning(f"æå–æ–‡ä»¶å…ƒæ•°æ®å¤±è´¥: {e}")
            
            # åˆ›å»ºä¸‹è½½ä»»åŠ¡è®°å½•
            task = DownloadTask(
                monitor_rule_id=rule.id,
                message_id=message.id,
                chat_id=str(message.chat_id) if hasattr(message, 'chat_id') else None,
                file_name=filename,
                file_type=media_info['type'],
                file_size_mb=media_info['size_mb'],
                file_unique_id=file_unique_id,
                file_access_hash=file_access_hash,
                media_json=media_json,
                status='pending',
                priority=0,
                total_bytes=media_info['size'],
                max_retries=self._get_config_value('max_retries', 3)
            )
            
            db.add(task)
            await db.commit()
            
            # åˆ·æ–°ä»»åŠ¡å¯¹è±¡ä»¥è·å–æ•°æ®åº“ç”Ÿæˆçš„ID
            try:
                await db.refresh(task)
            except Exception as refresh_error:
                # å¦‚æœåˆ·æ–°å¤±è´¥ï¼Œå°è¯•é‡æ–°æŸ¥è¯¢è·å–ID
                logger.warning(f"âš ï¸ åˆ·æ–°ä»»åŠ¡å¤±è´¥ï¼Œå°è¯•é‡æ–°æŸ¥è¯¢: {refresh_error}")
                result = await db.execute(
                    select(DownloadTask).where(
                        DownloadTask.file_unique_id == file_unique_id,
                        DownloadTask.monitor_rule_id == rule.id
                    ).order_by(DownloadTask.id.desc())
                )
                task = result.scalar_one_or_none()
                if not task:
                    raise Exception("æ— æ³•è·å–åˆ›å»ºçš„ä¸‹è½½ä»»åŠ¡")
            
            logger.info(f"ğŸ“¥ åˆ›å»ºä¸‹è½½ä»»åŠ¡: {filename} (ID: {task.id})")
            
            # æ·»åŠ åˆ°ä¸‹è½½é˜Ÿåˆ—ï¼ˆåŒ…å«client_wrapperï¼‰
            await self.download_queue.put({
                'task_id': task.id,
                'rule_id': rule.id,
                'message_id': message.id,
                'chat_id': message.chat_id if hasattr(message, 'chat_id') else None,
                'file_name': filename,
                'file_type': media_info['type'],
                'client': client,
                'message': message,
                'client_wrapper': client_wrapper  # ä¼ é€’å®¢æˆ·ç«¯åŒ…è£…å™¨
            })
            
        except Exception as e:
            logger.error(f"åˆ›å»ºä¸‹è½½ä»»åŠ¡å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            await db.rollback()
    
    async def _execute_download(self, task_data: Dict[str, Any]):
        """æ‰§è¡Œä¸‹è½½ä»»åŠ¡"""
        task_id = task_data['task_id']
        
        try:
            async for db in get_db():
                # è·å–ä»»åŠ¡å’Œè§„åˆ™
                result = await db.execute(
                    select(DownloadTask).where(DownloadTask.id == task_id)
                )
                task = result.scalar_one_or_none()
                
                if not task:
                    logger.warning(f"ä¸‹è½½ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
                    return
                
                result = await db.execute(
                    select(MediaMonitorRule).where(MediaMonitorRule.id == task.monitor_rule_id)
                )
                rule = result.scalar_one_or_none()
                
                if not rule:
                    logger.warning(f"ç›‘æ§è§„åˆ™ä¸å­˜åœ¨: {task.monitor_rule_id}")
                    return
                
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                task.status = 'downloading'
                task.started_at = datetime.now()
                await db.commit()
                
                # ç¡®ä¿ä¸‹è½½ç›®å½•å­˜åœ¨
                download_dir = Path(rule.temp_folder or '/app/media/downloads')
                download_dir.mkdir(parents=True, exist_ok=True)
                
                # ä¸‹è½½æ–‡ä»¶
                file_path = download_dir / task.file_name
                
                # æå‰è·å–å®¢æˆ·ç«¯ã€æ¶ˆæ¯å’ŒåŒ…è£…å™¨ï¼ˆé¿å…ä½œç”¨åŸŸé—®é¢˜ï¼‰
                client = task_data.get('client')
                message = task_data.get('message')
                client_wrapper = task_data.get('client_wrapper')
                
                # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä¸å®Œæ•´çš„æ–‡ä»¶ï¼Œå¦‚æœå­˜åœ¨åˆ™åˆ é™¤ï¼ˆPyrogramä¸æ”¯æŒçœŸæ­£çš„æ–­ç‚¹ç»­ä¼ ï¼‰
                skip_download = False
                if file_path.exists():
                    file_size = file_path.stat().st_size
                    expected_size = task.total_bytes or 0
                    if file_size < expected_size:
                        logger.warning(f"ğŸ—‘ï¸ å‘ç°ä¸å®Œæ•´çš„æ–‡ä»¶ {task.file_name} ({file_size}/{expected_size} bytes)ï¼Œåˆ é™¤é‡æ–°ä¸‹è½½")
                        file_path.unlink()
                    elif file_size == expected_size:
                        logger.info(f"âœ… æ–‡ä»¶å·²å­˜åœ¨ä¸”å®Œæ•´: {task.file_name}ï¼Œè·³è¿‡ä¸‹è½½ç›´æ¥æ•´ç†")
                        skip_download = True
                        # æ›´æ–°ä¸‹è½½è¿›åº¦
                        task.downloaded_bytes = expected_size
                        task.progress_percent = 100
                        await db.commit()
                
                if not skip_download:
                    logger.info(f"â¬‡ï¸ å¼€å§‹ä¸‹è½½: {task.file_name} -> {file_path}")
                    
                    # éªŒè¯å®¢æˆ·ç«¯å’Œæ¶ˆæ¯å¯¹è±¡
                    if not client or not message:
                        raise Exception("ç¼ºå°‘å®¢æˆ·ç«¯æˆ–æ¶ˆæ¯å¯¹è±¡")
                    
                    # æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦åŒ…å«åª’ä½“
                    logger.info(f"ğŸ“‹ æ¶ˆæ¯ä¿¡æ¯: ID={message.id if hasattr(message, 'id') else 'N/A'}, "
                               f"has_media={hasattr(message, 'media') and message.media is not None}, "
                               f"media_type={type(message.media).__name__ if hasattr(message, 'media') and message.media else 'None'}")
                    
                    if not hasattr(message, 'media') or message.media is None:
                        raise Exception(f"æ¶ˆæ¯ä¸åŒ…å«åª’ä½“æ–‡ä»¶ï¼Œå¯èƒ½å·²è¢«åˆ é™¤ã€‚è¯·åˆ é™¤æ­¤ä»»åŠ¡ã€‚")
                    
                    # ä½¿ç”¨å®¢æˆ·ç«¯åŒ…è£…å™¨çš„äº‹ä»¶å¾ªç¯ä¸‹è½½ï¼ˆé¿å…äº‹ä»¶å¾ªç¯å†²çªï¼‰
                    if client_wrapper and hasattr(client_wrapper, 'loop') and client_wrapper.loop:
                        # åœ¨å®¢æˆ·ç«¯çš„äº‹ä»¶å¾ªç¯ä¸­æ‰§è¡Œä¸‹è½½
                        import asyncio
                        from concurrent.futures import TimeoutError as FutureTimeoutError
                        
                        # å®šä¹‰è¿›åº¦å›è°ƒå‡½æ•°
                        last_progress_log = [0]  # ä½¿ç”¨åˆ—è¡¨ä»¥ä¾¿åœ¨é—­åŒ…ä¸­ä¿®æ”¹
                        last_db_update = [0]  # ä¸Šæ¬¡æ›´æ–°æ•°æ®åº“çš„æ—¶é—´
                        
                        def progress_callback(current, total):
                            percent = (current / total * 100) if total > 0 else 0
                            current_mb = current / 1024 / 1024
                            total_mb = total / 1024 / 1024
                            
                            # æ¯5%è®°å½•ä¸€æ¬¡æ—¥å¿—ï¼ˆå¤§æ–‡ä»¶ä¹Ÿèƒ½åŠæ—¶çœ‹åˆ°è¿›åº¦ï¼‰
                            progress_step = int(percent / 5)
                            if progress_step > last_progress_log[0]:
                                last_progress_log[0] = progress_step
                                logger.info(f"ğŸ“¥ ä¸‹è½½è¿›åº¦: {task.file_name} - {percent:.1f}% ({current_mb:.1f}MB/{total_mb:.1f}MB)")
                            
                            # æ¯2ç§’æ›´æ–°ä¸€æ¬¡æ•°æ®åº“ï¼ˆç»™å‰ç«¯å®æ—¶è¿›åº¦ï¼‰
                            import time
                            current_time = time.time()
                            if current_time - last_db_update[0] >= 2.0:
                                last_db_update[0] = current_time
                                # å¼‚æ­¥æ›´æ–°æ•°æ®åº“
                                asyncio.create_task(self._update_task_progress(task.id, percent, current, total))
                        
                        # ä¸‹è½½é‡è¯•é€»è¾‘ï¼ˆå¤„ç†ä»£ç†è¿æ¥å¤±è´¥ï¼‰
                        download_max_retries = 3
                        download_success = False
                        
                        for download_retry in range(download_max_retries):
                            try:
                                if download_retry > 0:
                                    logger.warning(f"ğŸ”„ ä¸‹è½½é‡è¯• {download_retry}/{download_max_retries-1}: {task.file_name}")
                                    # åˆ é™¤ä¸å®Œæ•´çš„æ–‡ä»¶
                                    if file_path.exists():
                                        os.remove(file_path)
                                    # ç­‰å¾…5ç§’è®©ä»£ç†æ¢å¤ï¼ˆä½¿ç”¨å¼‚æ­¥sleepï¼‰
                                    await asyncio.sleep(5)
                                
                                # ä½¿ç”¨å¼‚æ­¥Futureï¼Œé¿å…é˜»å¡
                                # Telethon API: download_media(message, file=path, progress_callback=callback)
                                future = asyncio.run_coroutine_threadsafe(
                                    client.download_media(
                                        message, 
                                        file=str(file_path),
                                        progress_callback=progress_callback
                                    ),
                                    client_wrapper.loop
                                )
                                
                                # å¼‚æ­¥ç­‰å¾…ï¼Œä¸é˜»å¡äº‹ä»¶å¾ªç¯ï¼ˆè¶…æ—¶2å°æ—¶ï¼Œé€‚åˆGBçº§å¤§è§†é¢‘ï¼‰
                                loop = asyncio.get_event_loop()
                                result = await asyncio.wait_for(
                                    asyncio.wrap_future(future),
                                    timeout=7200
                                )
                                logger.info(f"ğŸ“¦ download_media è¿”å›å€¼: {result}, ç±»å‹: {type(result)}")
                                download_success = True
                                break
                                
                            except (asyncio.TimeoutError, Exception) as download_error:
                                error_msg = str(download_error)
                                if download_retry < download_max_retries - 1:
                                    logger.warning(f"âš ï¸ ä¸‹è½½å¤±è´¥: {error_msg[:100]}, å‡†å¤‡é‡è¯•...")
                                else:
                                    logger.error(f"âŒ ä¸‹è½½å¤±è´¥ï¼ˆå·²é‡è¯•{download_max_retries}æ¬¡ï¼‰: {error_msg[:200]}")
                                    raise Exception(f"ä¸‹è½½å¤±è´¥ï¼ˆå·²é‡è¯•{download_max_retries}æ¬¡ï¼‰: {error_msg[:100]}")
                        
                        if not download_success:
                            raise Exception("ä¸‹è½½å¤±è´¥ï¼Œæ‰€æœ‰é‡è¯•å‡å¤±è´¥")
                    else:
                        # é™çº§æ–¹æ¡ˆï¼šç›´æ¥ä¸‹è½½ï¼ˆå¯èƒ½å¤±è´¥ï¼‰
                        await client.download_media(message, file=str(file_path))
                    
                    logger.info(f"âœ… ä¸‹è½½å®Œæˆ: {task.file_name}")
                
                # éªŒè¯æ–‡ä»¶æ˜¯å¦æˆåŠŸä¸‹è½½
                if not file_path.exists():
                    raise Exception("æ–‡ä»¶ä¸‹è½½å¤±è´¥ï¼Œæ–‡ä»¶ä¸å­˜åœ¨")
                
                # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
                file_hash = await self._calculate_file_hash(str(file_path))
                
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒå“ˆå¸Œçš„æ–‡ä»¶ï¼ˆå»é‡ï¼‰
                result = await db.execute(
                    select(MediaFile).where(MediaFile.file_hash == file_hash)
                )
                existing_file = result.scalar_one_or_none()
                
                if existing_file:
                    logger.info(f"â­ï¸ æ–‡ä»¶å·²å­˜åœ¨ï¼ˆå“ˆå¸Œç›¸åŒï¼‰ï¼Œè·³è¿‡: {task.file_name}")
                    # åˆ é™¤åˆšä¸‹è½½çš„é‡å¤æ–‡ä»¶
                    os.remove(file_path)
                    
                    # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºæˆåŠŸä½†è·³è¿‡
                    task.status = 'success'
                    task.completed_at = datetime.now()
                    task.progress_percent = 100
                    task.last_error = "æ–‡ä»¶å·²å­˜åœ¨ï¼ˆé‡å¤ï¼‰"
                    await db.commit()
                    
                    break
                
                # æå–å…ƒæ•°æ®ï¼ˆä½¿ç”¨å…¨å±€é…ç½®ï¼‰
                metadata_dict = {}
                extract_metadata = self._get_config_value('extract_metadata', True)
                metadata_mode = self._get_config_value('metadata_mode', 'lightweight')
                
                if extract_metadata and metadata_mode != 'disabled':
                    try:
                        async_extraction = self._get_config_value('async_metadata_extraction', True)
                        timeout = self._get_config_value('metadata_timeout', 10)
                        
                        if async_extraction:
                            # å¼‚æ­¥æå–ï¼Œä¸é˜»å¡
                            metadata_dict = await MediaMetadataExtractor.extract_metadata_async(
                                str(file_path),
                                mode=metadata_mode,
                                timeout=timeout
                            )
                        else:
                            # åŒæ­¥æå–
                            metadata_dict = await MediaMetadataExtractor.extract_metadata_async(
                                str(file_path),
                                mode=metadata_mode,
                                timeout=timeout
                            )
                        
                        logger.info(f"ğŸ“Š å…ƒæ•°æ®æå–å®Œæˆ: {metadata_dict.get('type', 'unknown')}")
                    except Exception as meta_error:
                        logger.warning(f"å…ƒæ•°æ®æå–å¤±è´¥: {meta_error}")
                        metadata_dict = {'error': str(meta_error)}
                
                # è·å–å‘é€è€…å’Œæ¥æºä¿¡æ¯
                sender_info = SenderFilter.get_sender_info(message)
                
                # è·å–èŠå¤©åç§°ï¼ˆä¼˜å…ˆä»messageå¯¹è±¡ï¼‰
                chat_name = 'unknown'
                if hasattr(message, 'chat') and message.chat:
                    chat = message.chat
                    # å°è¯•è·å–èŠå¤©æ ‡é¢˜æˆ–ç”¨æˆ·å
                    if hasattr(chat, 'title') and chat.title:
                        chat_name = chat.title
                    elif hasattr(chat, 'username') and chat.username:
                        chat_name = chat.username
                    elif hasattr(chat, 'first_name'):
                        chat_name = chat.first_name
                        if hasattr(chat, 'last_name') and chat.last_name:
                            chat_name += f" {chat.last_name}"
                
                logger.info(f"ğŸ“ èŠå¤©åç§°: {chat_name}, èŠå¤©ID: {task.chat_id}")
                
                # å‡†å¤‡å½’æ¡£å…ƒæ•°æ®
                # æ„å»ºå‘é€è€…æ˜¾ç¤ºåç§°ï¼ˆä¼˜å…ˆçº§ï¼šusername > å§“å > IDï¼‰
                sender_display = sender_info.get('username')
                if not sender_display:
                    # æ„å»ºå…¨åï¼ˆåªåŒ…å«éç©ºéƒ¨åˆ†ï¼‰
                    name_parts = []
                    if sender_info.get('first_name'):
                        name_parts.append(sender_info['first_name'])
                    if sender_info.get('last_name'):
                        name_parts.append(sender_info['last_name'])
                    sender_display = ' '.join(name_parts) if name_parts else None
                if not sender_display:
                    sender_display = str(sender_info.get('id', 'unknown'))
                
                logger.info(f"ğŸ‘¤ å‘é€è€…æ˜¾ç¤ºåç§°: {sender_display}, å‘é€è€…ID: {sender_info.get('id')}")
                
                organize_metadata = {
                    'type': task.file_type,
                    'sender_id': sender_info['id'],
                    'sender_username': sender_info.get('username'),
                    'sender_name': sender_display,  # æ–°å¢ï¼šå‘é€è€…æ˜¾ç¤ºåç§°
                    'source_chat': chat_name,
                    'source_chat_id': str(task.chat_id) if task.chat_id else 'unknown'
                }
                
                # åˆå§‹åŒ–å½’æ¡£ç›¸å…³å˜é‡
                final_path = None
                pan115_path = None
                is_uploaded = False
                organize_failed = False
                organize_error = None
                
                # æ£€æŸ¥å½’æ¡£ç›®æ ‡ç±»å‹
                should_upload_to_115 = rule.organize_enabled and rule.organize_target_type == 'pan115'
                should_organize_local = rule.organize_enabled and rule.organize_target_type != 'pan115'
                
                # æœ¬åœ°å½’æ¡£ï¼ˆä»…å½“ç›®æ ‡ä¸æ˜¯115ç½‘ç›˜æ—¶ï¼‰
                if should_organize_local:
                    try:
                        final_path = await FileOrganizer.organize_file(
                            rule,
                            str(file_path),
                            organize_metadata
                        )
                        
                        if final_path:
                            logger.info(f"ğŸ“¦ æ–‡ä»¶å·²å½’æ¡£åˆ°æœ¬åœ°: {final_path}")
                    except Exception as e:
                        logger.error(f"âŒ æœ¬åœ°å½’æ¡£å¤±è´¥: {e}")
                        organize_failed = True
                        organize_error = f"æœ¬åœ°å½’æ¡£å¤±è´¥: {str(e)}"
                
                # ä¸Šä¼ åˆ°115ç½‘ç›˜ï¼ˆä½œä¸ºå½’æ¡£æ–¹å¼ï¼‰
                elif should_upload_to_115:
                    try:
                        # è·å–115ç½‘ç›˜é…ç½®
                        pan115_user_key = self._get_config_value('pan115_user_key')
                        pan115_remote_base = rule.pan115_remote_path or self._get_config_value('pan115_remote_path', '/Telegramåª’ä½“')
                        
                        if not pan115_user_key:
                            error_msg = "115ç½‘ç›˜æœªé…ç½®ï¼Œè¯·å…ˆåœ¨è®¾ç½®é¡µé¢æ‰«ç ç™»å½•115ç½‘ç›˜"
                            logger.warning(f"âš ï¸ {error_msg}")
                            organize_failed = True
                            organize_error = error_msg
                        else:
                            logger.info(f"ğŸ“¤ 115ç½‘ç›˜å½’æ¡£æ¨¡å¼")
                            
                            # ç”Ÿæˆè¿œç¨‹è·¯å¾„
                            remote_dir = FileOrganizer.generate_target_directory(rule, organize_metadata)
                            remote_filename = FileOrganizer.generate_filename(rule, task.file_name, organize_metadata)
                            
                            # å®Œæ•´çš„115ç½‘ç›˜ç›®æ ‡è·¯å¾„
                            remote_target_dir = os.path.join(pan115_remote_base, remote_dir).replace('\\', '/')
                            pan115_path = os.path.join(remote_target_dir, remote_filename).replace('\\', '/')
                            
                            # æºæ–‡ä»¶ï¼ˆç›´æ¥ä½¿ç”¨ä¸´æ—¶ä¸‹è½½æ–‡ä»¶ï¼‰
                            source_file = str(file_path)
                            
                            logger.info(f"ğŸ“¤ å‡†å¤‡ä¸Šä¼ åˆ°115ç½‘ç›˜: {remote_filename}")
                            logger.info(f"   æœ¬åœ°æ–‡ä»¶: {source_file}")
                            logger.info(f"   ç›®æ ‡è·¯å¾„: {pan115_path}")
                            
                            # ä½¿ç”¨P115Serviceä¸Šä¼ 
                            from services.p115_service import P115Service
                            p115 = P115Service()
                            
                            upload_result = await p115.upload_file(
                                cookies=pan115_user_key,
                                file_path=source_file,
                                target_dir=remote_target_dir,
                                file_name=remote_filename
                            )
                            
                            if upload_result.get('success'):
                                is_uploaded = True
                                pan115_path = pan115_path  # è®°å½•115ç½‘ç›˜è·¯å¾„
                                logger.info(f"âœ… æ–‡ä»¶å·²ä¸Šä¼ åˆ°115ç½‘ç›˜: {pan115_path}")
                                if upload_result.get('pickcode'):
                                    logger.info(f"ğŸ“ æ–‡ä»¶ID: {upload_result['pickcode']}")
                                if upload_result.get('is_quick'):
                                    logger.info("âš¡ ç§’ä¼ æˆåŠŸï¼ˆæ–‡ä»¶å·²å­˜åœ¨ï¼‰")
                            else:
                                error_msg = upload_result.get('message', 'æœªçŸ¥é”™è¯¯')
                                logger.warning(f"âš ï¸ 115ç½‘ç›˜ä¸Šä¼ å¤±è´¥: {error_msg}")
                                organize_failed = True
                                organize_error = f"115ç½‘ç›˜ä¸Šä¼ å¤±è´¥: {error_msg}"
                    
                    except Exception as pan115_error:
                        error_msg = str(pan115_error)
                        logger.error(f"âŒ 115ç½‘ç›˜ä¸Šä¼ å¼‚å¸¸: {error_msg}")
                        organize_failed = True
                        organize_error = f"115ç½‘ç›˜ä¸Šä¼ å¼‚å¸¸: {error_msg}"
                        import traceback
                        traceback.print_exc()
                
                # åˆ›å»ºåª’ä½“æ–‡ä»¶è®°å½•
                media_file = MediaFile(
                    monitor_rule_id=rule.id,
                    download_task_id=task.id,
                    message_id=message.id,
                    temp_path=str(file_path) if not final_path else None,
                    final_path=final_path,
                    pan115_path=pan115_path,
                    file_hash=file_hash,
                    file_name=task.file_name,
                    file_type=task.file_type,
                    file_size_mb=task.file_size_mb,
                    extension=Path(task.file_name).suffix,
                    original_name=task.file_name,
                    file_metadata=json.dumps(metadata_dict) if metadata_dict else None,
                    width=metadata_dict.get('width'),
                    height=metadata_dict.get('height'),
                    duration_seconds=int(metadata_dict.get('duration_seconds', 0)) if metadata_dict.get('duration_seconds') else None,
                    resolution=metadata_dict.get('resolution'),
                    codec=metadata_dict.get('codec'),
                    bitrate_kbps=metadata_dict.get('bitrate_kbps'),
                    source_chat=chat_name,  # ä½¿ç”¨èŠå¤©åç§°è€Œä¸æ˜¯ID
                    sender_id=str(sender_info['id']),
                    sender_username=sender_display,  # ä½¿ç”¨æ˜¾ç¤ºåç§°ï¼ˆusernameæˆ–å§“åï¼‰
                    is_organized=(bool(final_path) or is_uploaded) and not organize_failed,  # å½’æ¡£æˆåŠŸä¸”æœªå¤±è´¥
                    is_uploaded_to_cloud=is_uploaded,
                    organize_failed=organize_failed,
                    organize_error=organize_error,
                    organized_at=datetime.now() if (final_path or is_uploaded) and not organize_failed else None,
                    uploaded_at=datetime.now() if is_uploaded else None
                )
                
                db.add(media_file)
                
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                # ä¸‹è½½æˆåŠŸå°±æ ‡è®°ä¸ºsuccessï¼Œå½’æ¡£å¤±è´¥åªå½±å“åª’ä½“æ–‡ä»¶è®°å½•ï¼Œä¸å½±å“ä¸‹è½½ä»»åŠ¡çŠ¶æ€
                task.status = 'success'
                task.completed_at = datetime.now()
                task.progress_percent = 100
                
                # æ›´æ–°è§„åˆ™ç»Ÿè®¡
                rule.total_downloaded = (rule.total_downloaded or 0) + 1
                rule.total_size_mb = (rule.total_size_mb or 0) + task.file_size_mb
                rule.last_download_at = datetime.now()
                
                if organize_failed:
                    logger.warning(f"âš ï¸ ä¸‹è½½æˆåŠŸä½†å½’æ¡£å¤±è´¥: {task.file_name} - {organize_error}")
                else:
                    logger.info(f"ğŸ‰ ä¸‹è½½ä»»åŠ¡å®Œæˆ: {task.file_name}")
                
                await db.commit()
                
                break
                
        except Exception as e:
            logger.error(f"ä¸‹è½½ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
            try:
                async for db in get_db():
                    result = await db.execute(
                        select(DownloadTask).where(DownloadTask.id == task_id)
                    )
                    task = result.scalar_one_or_none()
                    
                    if task:
                        task.status = 'failed'
                        task.failed_at = datetime.now()
                        task.last_error = str(e)
                        task.retry_count = (task.retry_count or 0) + 1
                        
                        # å¦‚æœè¿˜å¯ä»¥é‡è¯•ï¼Œé‡æ–°åŠ å…¥é˜Ÿåˆ—
                        if task.retry_count < task.max_retries:
                            task.status = 'pending'
                            await self.download_queue.put(task_data)
                            logger.info(f"ğŸ”„ é‡è¯•ä¸‹è½½ä»»åŠ¡: {task.file_name} ({task.retry_count}/{task.max_retries})")
                        else:
                            # æ›´æ–°è§„åˆ™å¤±è´¥ç»Ÿè®¡
                            result = await db.execute(
                                select(MediaMonitorRule).where(MediaMonitorRule.id == task.monitor_rule_id)
                            )
                            rule = result.scalar_one_or_none()
                            if rule:
                                rule.failed_downloads = (rule.failed_downloads or 0) + 1
                        
                        await db.commit()
                    
                    break
            except Exception as update_error:
                logger.error(f"æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥: {update_error}")
    
    async def _calculate_file_hash(self, file_path: str) -> str:
        """è®¡ç®—æ–‡ä»¶çš„ SHA-256 å“ˆå¸Œå€¼"""
        try:
            sha256 = hashlib.sha256()
            
            with open(file_path, 'rb') as f:
                while chunk := f.read(8192):
                    sha256.update(chunk)
            
            return sha256.hexdigest()
        except Exception as e:
            logger.error(f"è®¡ç®—æ–‡ä»¶å“ˆå¸Œå¤±è´¥: {e}")
            return ""
    
    async def _update_task_progress(self, task_id: int, percent: float, current_bytes: int, total_bytes: int):
        """æ›´æ–°ä»»åŠ¡ä¸‹è½½è¿›åº¦åˆ°æ•°æ®åº“ï¼ˆç»™å‰ç«¯å®æ—¶æ˜¾ç¤ºï¼‰"""
        try:
            async for db in get_db():
                result = await db.execute(
                    select(DownloadTask).where(DownloadTask.id == task_id)
                )
                task = result.scalar_one_or_none()
                
                if task:
                    task.progress_percent = int(percent)
                    task.downloaded_bytes = current_bytes
                    task.total_bytes = total_bytes
                    await db.commit()
                
                break
        except Exception as e:
            # è¿›åº¦æ›´æ–°å¤±è´¥ä¸å½±å“ä¸‹è½½ï¼Œåªè®°å½•è­¦å‘Š
            logger.debug(f"æ›´æ–°ä»»åŠ¡è¿›åº¦å¤±è´¥: {e}")
    
    async def reload_rule(self, rule_id: int):
        """é‡æ–°åŠ è½½å•ä¸ªç›‘æ§è§„åˆ™"""
        try:
            async for db in get_db():
                result = await db.execute(
                    select(MediaMonitorRule).where(MediaMonitorRule.id == rule_id)
                )
                rule = result.scalar_one_or_none()
                
                if rule and rule.is_active:
                    self.active_monitors[rule_id] = True
                    logger.info(f"âœ… é‡æ–°åŠ è½½ç›‘æ§è§„åˆ™: {rule.name} (ID: {rule.id})")
                elif rule_id in self.active_monitors:
                    del self.active_monitors[rule_id]
                    logger.info(f"â¸ï¸ åœç”¨ç›‘æ§è§„åˆ™: ID {rule_id}")
                
                break
                
        except Exception as e:
            logger.error(f"é‡æ–°åŠ è½½ç›‘æ§è§„åˆ™å¤±è´¥: {e}")


# å…¨å±€åª’ä½“ç›‘æ§æœåŠ¡å®ä¾‹
_media_monitor_service: Optional[MediaMonitorService] = None


def get_media_monitor_service() -> MediaMonitorService:
    """è·å–åª’ä½“ç›‘æ§æœåŠ¡å•ä¾‹"""
    global _media_monitor_service
    
    if _media_monitor_service is None:
        _media_monitor_service = MediaMonitorService()
    
    return _media_monitor_service

