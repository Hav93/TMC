#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¶ˆæ¯æ—¥å¿—APIè·¯ç”±

ç®¡ç†æ¶ˆæ¯è½¬å‘æ—¥å¿—
"""

from fastapi import APIRouter, Query, Request, Body, Depends
from fastapi.responses import JSONResponse, StreamingResponse
from datetime import datetime
from typing import Optional, Dict, Any, List
from log_manager import get_logger
from sqlalchemy import select, desc, and_, func
from auth import get_current_user
from models import User
import json
import io

logger = get_logger('api.logs', 'api.log')

router = APIRouter()


@router.get("")
async def list_logs(
    page: int = Query(1, ge=1, description="é¡µç "),
    limit: int = Query(50, ge=1, le=5000, description="æ¯é¡µæ•°é‡"),
    status: Optional[str] = Query(None, description="çŠ¶æ€ç­›é€‰"),
    rule_id: Optional[int] = Query(None, description="è§„åˆ™IDç­›é€‰"),
    start_date: Optional[str] = Query(None, description="å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)"),
    end_date: Optional[str] = Query(None, description="ç»“æŸæ—¥æœŸ (YYYY-MM-DD)")
):
    """
    è·å–æ¶ˆæ¯æ—¥å¿—åˆ—è¡¨
    
    æ”¯æŒåˆ†é¡µã€ç­›é€‰ã€æ—¥æœŸèŒƒå›´æŸ¥è¯¢
    """
    try:
        from models import MessageLog
        from database import get_db
        from sqlalchemy.orm import joinedload
        
        async for db in get_db():
            # æ„å»ºæŸ¥è¯¢
            query = select(MessageLog)
            
            # çŠ¶æ€ç­›é€‰
            if status:
                query = query.where(MessageLog.status == status)
            
            # è§„åˆ™IDç­›é€‰
            if rule_id:
                query = query.where(MessageLog.rule_id == rule_id)
            
            # æ—¥æœŸèŒƒå›´ç­›é€‰
            if start_date or end_date:
                date_conditions = []
                if start_date:
                    try:
                        start_dt = datetime.strptime(start_date, '%Y-%m-%d').date()
                        date_conditions.append(func.date(MessageLog.created_at) >= start_dt)
                    except ValueError:
                        logger.warning(f"æ— æ•ˆçš„å¼€å§‹æ—¥æœŸæ ¼å¼: {start_date}")
                
                if end_date:
                    try:
                        end_dt = datetime.strptime(end_date, '%Y-%m-%d').date()
                        date_conditions.append(func.date(MessageLog.created_at) <= end_dt)
                    except ValueError:
                        logger.warning(f"æ— æ•ˆçš„ç»“æŸæ—¥æœŸæ ¼å¼: {end_date}")
                
                if date_conditions:
                    query = query.where(and_(*date_conditions))
            
            # æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            query = query.order_by(desc(MessageLog.created_at))
            
            # åˆ†é¡µ
            offset = (page - 1) * limit
            paginated_query = query.offset(offset).limit(limit)
            
            # æ‰§è¡ŒæŸ¥è¯¢ï¼Œé¢„åŠ è½½è§„åˆ™ä¿¡æ¯
            paginated_query = paginated_query.options(joinedload(MessageLog.rule))
            result = await db.execute(paginated_query)
            logs = result.scalars().all()
            
            # è·å–æ€»æ•°ï¼ˆåº”ç”¨ç›¸åŒçš„ç­›é€‰æ¡ä»¶ï¼‰
            count_query = select(MessageLog)
            if status:
                count_query = count_query.where(MessageLog.status == status)
            if rule_id:
                count_query = count_query.where(MessageLog.rule_id == rule_id)
            
            # æ—¥æœŸèŒƒå›´ç­›é€‰ï¼ˆé‡è¦ï¼šæ€»æ•°ä¹Ÿè¦åº”ç”¨æ—¥æœŸè¿‡æ»¤ï¼‰
            if start_date or end_date:
                date_conditions = []
                if start_date:
                    try:
                        start_dt = datetime.strptime(start_date, '%Y-%m-%d').date()
                        date_conditions.append(func.date(MessageLog.created_at) >= start_dt)
                    except ValueError:
                        pass
                
                if end_date:
                    try:
                        end_dt = datetime.strptime(end_date, '%Y-%m-%d').date()
                        date_conditions.append(func.date(MessageLog.created_at) <= end_dt)
                    except ValueError:
                        pass
                
                if date_conditions:
                    count_query = count_query.where(and_(*date_conditions))
            count_result = await db.execute(count_query)
            total = len(count_result.scalars().all())
            
            # è°ƒè¯•æ—¥å¿—
            logger.info(f"ğŸ“Š æ—¥å¿—æŸ¥è¯¢: page={page}, limit={limit}, status={status}, rule_id={rule_id}, start_date={start_date}, end_date={end_date}")
            logger.info(f"ğŸ“Š æŸ¥è¯¢ç»“æœ: è¿”å› {len(logs)} æ¡, æ€»è®¡ {total} æ¡")
            
            # åºåˆ—åŒ–æ—¥å¿—æ•°æ®
            logs_data = []
            for log in logs:
                # è·å–è§„åˆ™åç§°ï¼ˆé€šè¿‡é¢„åŠ è½½çš„å…³ç³»ï¼‰
                rule_name = None
                if log.rule and hasattr(log.rule, 'name'):
                    rule_name = log.rule.name
                elif log.rule_id:
                    rule_name = f"è§„åˆ™ #{log.rule_id}"
                
                log_data = {
                    "id": log.id,
                    "rule_id": log.rule_id,
                    "rule_name": rule_name,
                    # å‰ç«¯æœŸæœ›çš„å­—æ®µåæ˜ å°„
                    "message_id": log.source_message_id,
                    "forwarded_message_id": log.target_message_id,
                    "source_chat_id": log.source_chat_id,
                    "source_chat_name": log.source_chat_name,
                    "target_chat_id": log.target_chat_id,
                    "target_chat_name": log.target_chat_name,
                    "message_text": log.original_text,
                    "message_type": log.media_type or 'text',
                    "status": log.status,
                    "error_message": log.error_message,
                    "processing_time": log.processing_time,
                    "created_at": log.created_at.isoformat() if log.created_at else None
                }
                logs_data.append(log_data)
            
            return JSONResponse(content={
                "success": True,
                "items": logs_data,  # å‰ç«¯æœŸæœ› items å­—æ®µ
                "total": total,
                "page": page,
                "limit": limit
            })
    except Exception as e:
        logger.error(f"è·å–æ—¥å¿—å¤±è´¥: {e}")
        return JSONResponse(content={
            "success": False,
            "message": f"è·å–æ—¥å¿—å¤±è´¥: {str(e)}"
        }, status_code=500)


@router.get("/stats")
async def get_log_stats():
    """
    è·å–æ—¥å¿—ç»Ÿè®¡ä¿¡æ¯
    
    è¿”å›å„çŠ¶æ€çš„æ—¥å¿—æ•°é‡ã€ä»Šæ—¥è½¬å‘æ•°ç­‰
    """
    try:
        from models import MessageLog
        from database import get_db
        from sqlalchemy import func
        from datetime import date
        
        async for db in get_db():
            # æŒ‰çŠ¶æ€ç»Ÿè®¡
            status_stats_query = select(
                MessageLog.status,
                func.count(MessageLog.id).label('count')
            ).group_by(MessageLog.status)
            status_result = await db.execute(status_stats_query)
            status_stats = {row[0]: row[1] for row in status_result.fetchall()}
            
            # ä»Šæ—¥ç»Ÿè®¡
            today = date.today()
            today_query = select(func.count(MessageLog.id)).where(
                func.date(MessageLog.created_at) == today
            )
            today_result = await db.execute(today_query)
            today_count = today_result.scalar() or 0
            
            # æ€»è®¡
            total_query = select(func.count(MessageLog.id))
            total_result = await db.execute(total_query)
            total_count = total_result.scalar() or 0
            
            return JSONResponse(content={
                "success": True,
                "stats": {
                    "total": total_count,
                    "today": today_count,
                    "by_status": status_stats
                }
            })
    except Exception as e:
        logger.error(f"è·å–æ—¥å¿—ç»Ÿè®¡å¤±è´¥: {e}")
        return JSONResponse(content={
            "success": False,
            "message": f"è·å–æ—¥å¿—ç»Ÿè®¡å¤±è´¥: {str(e)}"
        }, status_code=500)


@router.delete("/{log_id}")
async def delete_log(log_id: int):
    """
    åˆ é™¤å•æ¡æ—¥å¿—
    """
    try:
        from models import MessageLog
        from database import get_db
        from sqlalchemy import delete
        
        logger.info(f"ğŸ—‘ï¸ è¯·æ±‚åˆ é™¤æ—¥å¿—: ID={log_id}")
        
        async for db in get_db():
            result = await db.execute(
                delete(MessageLog).where(MessageLog.id == log_id)
            )
            await db.commit()
            
            if result.rowcount > 0:
                logger.info(f"âœ… æ—¥å¿—åˆ é™¤æˆåŠŸ: ID={log_id}")
                return JSONResponse({
                    "success": True,
                    "message": "æ—¥å¿—åˆ é™¤æˆåŠŸ"
                })
            else:
                logger.warning(f"âš ï¸ æ—¥å¿—ä¸å­˜åœ¨: ID={log_id}")
                return JSONResponse(
                    status_code=404,
                    content={"success": False, "message": "æ—¥å¿—ä¸å­˜åœ¨"}
                )
    except Exception as e:
        logger.error(f"âŒ åˆ é™¤æ—¥å¿—å¤±è´¥: {e}")
        return JSONResponse(
            status_code=500,
            content={"success": False, "message": f"åˆ é™¤æ—¥å¿—å¤±è´¥: {str(e)}"}
        )


@router.post("/batch-delete")
async def batch_delete_logs(request: Request):
    """
    æ‰¹é‡åˆ é™¤æ—¥å¿—
    """
    try:
        from models import MessageLog
        from database import get_db
        from sqlalchemy import delete
        
        body = await request.json()
        ids = body.get('ids', [])
        
        logger.info(f"ğŸ—‘ï¸ è¯·æ±‚æ‰¹é‡åˆ é™¤æ—¥å¿—: IDs={ids}, å…± {len(ids)} æ¡")
        
        if not ids:
            logger.warning("âš ï¸ æ‰¹é‡åˆ é™¤è¯·æ±‚ä¸­æ²¡æœ‰æä¾›IDåˆ—è¡¨")
            return JSONResponse({
                "success": False,
                "message": "è¯·æä¾›è¦åˆ é™¤çš„æ—¥å¿—IDåˆ—è¡¨"
            }, status_code=400)
        
        async for db in get_db():
            result = await db.execute(
                delete(MessageLog).where(MessageLog.id.in_(ids))
            )
            await db.commit()
            
            logger.info(f"âœ… æ‰¹é‡åˆ é™¤æ—¥å¿—æˆåŠŸ: è¯·æ±‚åˆ é™¤ {len(ids)} æ¡ï¼Œå®é™…åˆ é™¤ {result.rowcount} æ¡")
            return JSONResponse({
                "success": True,
                "message": f"æˆåŠŸåˆ é™¤ {result.rowcount} æ¡æ—¥å¿—"
            })
    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡åˆ é™¤æ—¥å¿—å¤±è´¥: {e}")
        return JSONResponse(
            status_code=500,
            content={"success": False, "message": f"æ‰¹é‡åˆ é™¤æ—¥å¿—å¤±è´¥: {str(e)}"}
        )


@router.post("/export")
async def export_logs(
    filters: Optional[Dict[str, Any]] = Body(default={}),
    current_user: User = Depends(get_current_user)
):
    """
    å¯¼å‡ºæ—¥å¿—ä¸ºJSONæ–‡ä»¶
    
    æ”¯æŒä¸list_logsç›¸åŒçš„ç­›é€‰å‚æ•°
    éœ€è¦ç™»å½•è®¤è¯
    """
    try:
        from models import MessageLog
        from database import get_db
        
        async for db in get_db():
            # æ„å»ºæŸ¥è¯¢ï¼ˆä¸list_logsç±»ä¼¼ï¼Œä½†ä¸åˆ†é¡µï¼‰
            query = select(MessageLog).order_by(desc(MessageLog.created_at))
            
            # åº”ç”¨ç­›é€‰
            conditions = []
            
            if filters.get('status'):
                conditions.append(MessageLog.status == filters['status'])
            
            if filters.get('rule_id'):
                conditions.append(MessageLog.rule_id == filters['rule_id'])
            
            if filters.get('start_date'):
                try:
                    start_dt = datetime.strptime(filters['start_date'], '%Y-%m-%d')
                    conditions.append(MessageLog.created_at >= start_dt)
                except ValueError:
                    pass
            
            if filters.get('end_date'):
                try:
                    # ç»“æŸæ—¥æœŸåŒ…å«å½“å¤©å…¨å¤©
                    end_dt = datetime.strptime(filters['end_date'], '%Y-%m-%d')
                    end_dt = end_dt.replace(hour=23, minute=59, second=59)
                    conditions.append(MessageLog.created_at <= end_dt)
                except ValueError:
                    pass
            
            if conditions:
                query = query.where(and_(*conditions))
            
            # æ‰§è¡ŒæŸ¥è¯¢
            result = await db.execute(query)
            logs = result.scalars().all()
            
            # è½¬æ¢ä¸ºJSONæ ¼å¼
            logs_data = []
            for log in logs:
                logs_data.append({
                    'id': log.id,
                    'rule_id': log.rule_id,
                    'rule_name': log.rule_name,
                    'source_chat_id': log.source_chat_id,
                    'source_chat_name': log.source_chat_name,
                    'source_message_id': log.source_message_id,
                    'target_chat_id': log.target_chat_id,
                    'target_chat_name': log.target_chat_name,
                    'target_message_id': log.target_message_id,
                    'original_text': log.original_text,
                    'processed_text': log.processed_text,
                    'media_type': log.media_type,
                    'status': log.status,
                    'error_message': log.error_message,
                    'processing_time': log.processing_time,
                    'content_hash': log.content_hash,
                    'media_hash': log.media_hash,
                    'sender_id': log.sender_id,
                    'sender_username': log.sender_username,
                    'created_at': log.created_at.isoformat() if log.created_at else None,
                })
            
            # ç”ŸæˆJSONæ–‡ä»¶
            json_str = json.dumps(logs_data, ensure_ascii=False, indent=2)
            json_bytes = json_str.encode('utf-8')
            
            logger.info(f"å¯¼å‡ºæ—¥å¿—æˆåŠŸ: {len(logs_data)} æ¡è®°å½•")
            
            # è¿”å›æ–‡ä»¶æµ
            return StreamingResponse(
                io.BytesIO(json_bytes),
                media_type='application/json',
                headers={
                    'Content-Disposition': f'attachment; filename="logs_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json"'
                }
            )
    except Exception as e:
        logger.error(f"å¯¼å‡ºæ—¥å¿—å¤±è´¥: {e}")
        return JSONResponse(
            status_code=500,
            content={"success": False, "message": f"å¯¼å‡ºæ—¥å¿—å¤±è´¥: {str(e)}"}
        )


@router.post("/import")
async def import_logs(
    data: List[Dict[str, Any]] = Body(..., embed=True),
    current_user: User = Depends(get_current_user)
):
    """
    å¯¼å…¥æ—¥å¿—è®°å½•
    
    ä»JSONæ ¼å¼å¯¼å…¥æ—¥å¿—ï¼Œæ”¯æŒæ‰¹é‡å¯¼å…¥
    éœ€è¦ç™»å½•è®¤è¯
    """
    try:
        from models import MessageLog
        from database import get_db
        
        if not data:
            return JSONResponse({
                "success": False,
                "message": "å¯¼å…¥æ•°æ®ä¸ºç©º"
            })
        
        async for db in get_db():
            imported_count = 0
            
            for log_data in data:
                try:
                    # åˆ›å»ºæ—¥å¿—è®°å½•ï¼ˆä½¿ç”¨æ­£ç¡®çš„å­—æ®µåï¼‰
                    new_log = MessageLog(
                        rule_id=log_data.get("rule_id"),
                        rule_name=log_data.get("rule_name"),
                        source_chat_id=log_data.get("source_chat_id", ""),
                        source_chat_name=log_data.get("source_chat_name"),
                        source_message_id=log_data.get("source_message_id", 0),
                        target_chat_id=log_data.get("target_chat_id", ""),
                        target_chat_name=log_data.get("target_chat_name"),
                        target_message_id=log_data.get("target_message_id"),
                        original_text=log_data.get("original_text"),
                        processed_text=log_data.get("processed_text"),
                        media_type=log_data.get("media_type"),
                        status=log_data.get("status", "success"),
                        error_message=log_data.get("error_message"),
                        processing_time=log_data.get("processing_time"),
                        content_hash=log_data.get("content_hash"),
                        media_hash=log_data.get("media_hash"),
                        sender_id=log_data.get("sender_id"),
                        sender_username=log_data.get("sender_username"),
                    )
                    
                    # å¤„ç†æ—¶é—´å­—æ®µ
                    if log_data.get("created_at"):
                        from datetime import datetime
                        new_log.created_at = datetime.fromisoformat(log_data["created_at"])
                    
                    db.add(new_log)
                    imported_count += 1
                    
                except Exception as e:
                    logger.warning(f"å¯¼å…¥æ—¥å¿—å¤±è´¥ (è·³è¿‡): {log_data.get('id', 'Unknown')} - {e}")
                    continue
            
            await db.commit()
            
            logger.info(f"å¯¼å…¥æ—¥å¿—æˆåŠŸ: {imported_count}/{len(data)} æ¡")
            
            return JSONResponse({
                "success": True,
                "imported_count": imported_count,
                "message": f"æˆåŠŸå¯¼å…¥ {imported_count} æ¡æ—¥å¿—ï¼ˆæ€»å…± {len(data)} æ¡ï¼‰"
            })
            
    except Exception as e:
        logger.error(f"å¯¼å…¥æ—¥å¿—å¤±è´¥: {e}")
        return JSONResponse(
            status_code=500,
            content={"success": False, "message": f"å¯¼å…¥æ—¥å¿—å¤±è´¥: {str(e)}"}
        )


"""
âœ… æ‰€æœ‰æ—¥å¿—ç«¯ç‚¹å·²å®Œæˆ!

- GET /api/logs - è·å–æ—¥å¿—åˆ—è¡¨ (æ”¯æŒåˆ†é¡µã€ç­›é€‰ã€æ—¥æœŸèŒƒå›´)
- GET /api/logs/stats - è·å–æ—¥å¿—ç»Ÿè®¡
- DELETE /api/logs/{log_id} - åˆ é™¤å•æ¡æ—¥å¿—
- POST /api/logs/batch-delete - æ‰¹é‡åˆ é™¤æ—¥å¿—
- POST /api/logs/export - å¯¼å‡ºæ—¥å¿—ä¸ºJSONæ–‡ä»¶
- POST /api/logs/import - å¯¼å…¥æ—¥å¿—è®°å½•
"""