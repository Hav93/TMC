"""
æ—¥å¿—è§£æä¸èšåˆå·¥å…·

æä¾›ç»“æ„åŒ–çš„æ—¥å¿—è§£æã€åˆ†ç±»å’Œå®ä½“æå–åŠŸèƒ½
"""
import re
from typing import Dict, Any, Optional, List, Set
from datetime import datetime
from enum import Enum


class LogLevel(str, Enum):
    """æ—¥å¿—çº§åˆ«"""
    DEBUG = "DEBUG"
    INFO = "INFO"
    WARNING = "WARNING"
    ERROR = "ERROR"
    CRITICAL = "CRITICAL"


class ActionType(str, Enum):
    """æ“ä½œç±»å‹åˆ†ç±»"""
    FORWARD = "forward"              # è½¬å‘æ¶ˆæ¯
    CREATE = "create"                # åˆ›å»ºï¼ˆè§„åˆ™ã€ç”¨æˆ·ç­‰ï¼‰
    UPDATE = "update"                # æ›´æ–°
    DELETE = "delete"                # åˆ é™¤
    QUERY = "query"                  # æŸ¥è¯¢
    AUTH = "auth"                    # è®¤è¯
    ERROR = "error"                  # é”™è¯¯
    STARTUP = "startup"              # å¯åŠ¨
    SHUTDOWN = "shutdown"            # å…³é—­
    CONNECT = "connect"              # è¿æ¥
    DISCONNECT = "disconnect"        # æ–­å¼€
    FETCH = "fetch"                  # è·å–
    PROCESS = "process"              # å¤„ç†
    UNKNOWN = "unknown"              # æœªçŸ¥


class LogParser:
    """æ—¥å¿—è§£æå™¨ - å°†åŸå§‹æ—¥å¿—è§£æä¸ºç»“æ„åŒ–æ•°æ®"""
    
    # æ—¥å¿—æ ¼å¼ï¼š2025-10-06 22:45:40 | INFO | api.logs:list_logs:115 - ğŸ“Š æŸ¥è¯¢ç»“æœ: è¿”å› 2 æ¡ï¼Œæ€»è®¡ 2 æ¡
    LOG_PATTERN = re.compile(
        r'^(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}(?:\.\d+)?)\s*\|\s*'  # æ—¶é—´æˆ³
        r'(\w+)\s*\|\s*'                                                 # çº§åˆ«
        r'([\w\.]+):([\w_]+):(\d+)\s*-\s*'                              # æ¨¡å—:å‡½æ•°:è¡Œå·
        r'(.+)$'                                                         # æ¶ˆæ¯
    )
    
    # Emoji æå–ï¼ˆæ‰©å±•ç‰ˆï¼Œæ”¯æŒæ›´å¤šemojiï¼‰
    EMOJI_PATTERN = re.compile(
        r'[\U0001F300-\U0001F9FF]|[\u2600-\u26FF]|[\u2700-\u27BF]|'
        r'[\U0001FA70-\U0001FAFF]|[\u23E9-\u23FA]|[\u25AA-\u25FE]'
    )
    
    # JSON æ£€æµ‹
    JSON_PATTERN = re.compile(r'\{[^{}]*\}|\[[^\[\]]*\]')
    
    # å †æ ˆè·Ÿè¸ªæ£€æµ‹
    TRACEBACK_PATTERN = re.compile(r'Traceback \(most recent call last\):|File ".*", line \d+')
    
    # SQL æ£€æµ‹
    SQL_PATTERN = re.compile(r'\b(SELECT|INSERT|UPDATE|DELETE|FROM|WHERE|JOIN)\b', re.IGNORECASE)
    
    # URL æ£€æµ‹
    URL_PATTERN = re.compile(r'https?://[^\s]+')
    
    # æ–‡ä»¶è·¯å¾„æ£€æµ‹
    PATH_PATTERN = re.compile(r'(?:/|\\)(?:[\w\-\.]+(?:/|\\))+[\w\-\.]+')
    
    # å®ä½“æå–æ¨¡å¼
    ENTITY_PATTERNS = {
        'message_id': re.compile(r'æ¶ˆæ¯ID[:ï¼š\s]+(\d+)|message_id[:=\s]+(\d+)', re.IGNORECASE),
        'rule_id': re.compile(r'è§„åˆ™ID[:ï¼š\s]+(\d+)|rule_id[:=\s]+(\d+)', re.IGNORECASE),
        'rule_name': re.compile(r'è§„åˆ™[:ï¼š]\s*([^\s,ï¼Œ]+)|è§„åˆ™åç§°[:ï¼š]\s*([^\s,ï¼Œ]+)'),
        'chat_id': re.compile(r'èŠå¤©ID[:ï¼š\s]+(-?\d+)|chat_id[:=\s]+(-?\d+)', re.IGNORECASE),
        'source_chat': re.compile(r'æ¥æº[:ï¼š]\s*([^\sâ†’-]+)|from[:ï¼š]\s*([^\sâ†’-]+)', re.IGNORECASE),
        'target_chat': re.compile(r'ç›®æ ‡[:ï¼š]\s*([^\s,ï¼Œ]+)|to[:ï¼š]\s*([^\s,ï¼Œ]+)', re.IGNORECASE),
        'user_id': re.compile(r'ç”¨æˆ·ID[:ï¼š\s]+(\d+)|user_id[:=\s]+(\d+)', re.IGNORECASE),
        'username': re.compile(r'ç”¨æˆ·[:ï¼š]\s*([^\s,ï¼Œ]+)|username[:ï¼š]\s*([^\s,ï¼Œ]+)', re.IGNORECASE),
        'count': re.compile(r'(\d+)\s*æ¡|è¿”å›\s*(\d+)|æ€»è®¡\s*(\d+)'),
        'duration': re.compile(r'è€—æ—¶[:ï¼š]?\s*(\d+(?:\.\d+)?)\s*(ms|s|ç§’|æ¯«ç§’)'),
    }
    
    # æ“ä½œç±»å‹å…³é”®è¯æ˜ å°„
    ACTION_KEYWORDS = {
        ActionType.FORWARD: ['è½¬å‘', 'forward', 'å‘é€æ¶ˆæ¯', 'send_message'],
        ActionType.CREATE: ['åˆ›å»º', 'create', 'æ·»åŠ ', 'add', 'æ–°å¢', 'new'],
        ActionType.UPDATE: ['æ›´æ–°', 'update', 'ä¿®æ”¹', 'modify', 'edit'],
        ActionType.DELETE: ['åˆ é™¤', 'delete', 'ç§»é™¤', 'remove'],
        ActionType.QUERY: ['æŸ¥è¯¢', 'query', 'è·å–', 'get', 'åˆ—è¡¨', 'list'],
        ActionType.AUTH: ['ç™»å½•', 'login', 'è®¤è¯', 'auth', 'æˆæƒ', 'authorize', 'æœªæˆæƒ', 'unauthorized'],
        ActionType.STARTUP: ['å¯åŠ¨', 'startup', 'start', 'åˆå§‹åŒ–', 'init'],
        ActionType.SHUTDOWN: ['å…³é—­', 'shutdown', 'stop', 'åœæ­¢'],
        ActionType.CONNECT: ['è¿æ¥', 'connect', 'å·²è¿æ¥'],
        ActionType.DISCONNECT: ['æ–­å¼€', 'disconnect', 'æ–­çº¿'],
        ActionType.FETCH: ['æ‹‰å–', 'fetch', 'åŒæ­¥', 'sync'],
        ActionType.PROCESS: ['å¤„ç†', 'process', 'æ‰§è¡Œ', 'execute'],
        ActionType.ERROR: ['é”™è¯¯', 'error', 'å¤±è´¥', 'failed', 'å¼‚å¸¸', 'exception'],
    }
    
    @classmethod
    def detect_content_type(cls, message: str) -> List[str]:
        """
        æ£€æµ‹æ¶ˆæ¯ä¸­åŒ…å«çš„ç‰¹æ®Šå†…å®¹ç±»å‹
        
        Returns:
            å†…å®¹ç±»å‹åˆ—è¡¨ï¼Œå¦‚ ['json', 'url', 'traceback']
        """
        content_types = []
        
        if cls.JSON_PATTERN.search(message):
            content_types.append('json')
        
        if cls.TRACEBACK_PATTERN.search(message):
            content_types.append('traceback')
        
        if cls.SQL_PATTERN.search(message):
            content_types.append('sql')
        
        if cls.URL_PATTERN.search(message):
            content_types.append('url')
        
        if cls.PATH_PATTERN.search(message):
            content_types.append('path')
        
        return content_types
    
    @classmethod
    def extract_special_content(cls, message: str) -> Dict[str, List[str]]:
        """
        æå–æ¶ˆæ¯ä¸­çš„ç‰¹æ®Šå†…å®¹
        
        Returns:
            åŒ…å«å„ç§ç‰¹æ®Šå†…å®¹çš„å­—å…¸
        """
        special_content = {}
        
        # æå– JSON
        json_matches = cls.JSON_PATTERN.findall(message)
        if json_matches:
            special_content['json'] = json_matches
        
        # æå– URL
        url_matches = cls.URL_PATTERN.findall(message)
        if url_matches:
            special_content['urls'] = url_matches
        
        # æå–æ–‡ä»¶è·¯å¾„
        path_matches = cls.PATH_PATTERN.findall(message)
        if path_matches:
            special_content['paths'] = path_matches
        
        return special_content
    
    @classmethod
    def parse(cls, raw_line: str) -> Dict[str, Any]:
        """
        è§£æå•è¡Œæ—¥å¿—ï¼Œè¿”å›ç»“æ„åŒ–æ•°æ®
        
        Args:
            raw_line: åŸå§‹æ—¥å¿—è¡Œ
            
        Returns:
            ç»“æ„åŒ–çš„æ—¥å¿—æ•°æ®
        """
        # åŒ¹é…æ—¥å¿—æ ¼å¼
        match = cls.LOG_PATTERN.match(raw_line.strip())
        
        if not match:
            # å¦‚æœä¸åŒ¹é…æ ‡å‡†æ ¼å¼ï¼Œè¿”å›ç®€åŒ–ç»“æ„
            return {
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'level': LogLevel.INFO,
                'module': 'unknown',
                'function': 'unknown',
                'line_number': 0,
                'message': raw_line.strip(),
                'emoji': None,
                'action_type': ActionType.UNKNOWN,
                'entities': {},
                'severity_score': 0,
                'raw': raw_line.strip()
            }
        
        timestamp, level, module, function, line_number, message = match.groups()
        
        # æ ‡å‡†åŒ–çº§åˆ«
        try:
            log_level = LogLevel(level.upper())
        except ValueError:
            log_level = LogLevel.INFO
        
        # æå– emoji
        emoji = cls._extract_emoji(message)
        
        # åˆ†ç±»æ“ä½œç±»å‹
        action_type = cls._classify_action(message, log_level)
        
        # æå–å®ä½“
        entities = cls._extract_entities(message)
        
        # è®¡ç®—ä¸¥é‡æ€§åˆ†æ•°
        severity_score = cls._calculate_severity(log_level, action_type, message)
        
        # æ£€æµ‹å†…å®¹ç±»å‹
        content_types = cls.detect_content_type(message)
        
        # æå–ç‰¹æ®Šå†…å®¹
        special_content = cls.extract_special_content(message)
        
        # æ™ºèƒ½æ ¼å¼åŒ–æ¶ˆæ¯
        formatted_message = cls._format_message(message, content_types)
        
        return {
            'timestamp': timestamp,
            'level': log_level.value,
            'module': module,
            'function': function,
            'line_number': int(line_number),
            'message': message,
            'formatted_message': formatted_message,  # æ ¼å¼åŒ–åçš„æ¶ˆæ¯
            'emoji': emoji,
            'action_type': action_type.value,
            'entities': entities,
            'severity_score': severity_score,
            'content_types': content_types,  # å†…å®¹ç±»å‹åˆ—è¡¨
            'special_content': special_content,  # ç‰¹æ®Šå†…å®¹
            'raw': raw_line.strip()
        }
    
    @classmethod
    def _extract_emoji(cls, message: str) -> Optional[str]:
        """æå–æ¶ˆæ¯ä¸­çš„ç¬¬ä¸€ä¸ª emoji"""
        match = cls.EMOJI_PATTERN.search(message)
        return match.group(0) if match else None
    
    @classmethod
    def _classify_action(cls, message: str, level: LogLevel) -> ActionType:
        """æ ¹æ®æ¶ˆæ¯å†…å®¹å’Œçº§åˆ«åˆ†ç±»æ“ä½œç±»å‹"""
        message_lower = message.lower()
        
        # ä¼˜å…ˆåŒ¹é…é”™è¯¯
        if level in [LogLevel.ERROR, LogLevel.CRITICAL]:
            return ActionType.ERROR
        
        # åŒ¹é…å…³é”®è¯
        for action_type, keywords in cls.ACTION_KEYWORDS.items():
            for keyword in keywords:
                if keyword in message_lower:
                    return action_type
        
        return ActionType.UNKNOWN
    
    @classmethod
    def _extract_entities(cls, message: str) -> Dict[str, Any]:
        """ä»æ¶ˆæ¯ä¸­æå–å®ä½“ä¿¡æ¯"""
        entities = {}
        
        for entity_name, pattern in cls.ENTITY_PATTERNS.items():
            match = pattern.search(message)
            if match:
                # è·å–ç¬¬ä¸€ä¸ªéNoneçš„æ•è·ç»„
                value = next((g for g in match.groups() if g is not None), None)
                if value:
                    # å°è¯•è½¬æ¢ä¸ºæ•°å­—
                    try:
                        if entity_name in ['message_id', 'rule_id', 'chat_id', 'user_id', 'count', 'line_number']:
                            entities[entity_name] = int(value)
                        elif entity_name == 'duration':
                            # ç»Ÿä¸€è½¬æ¢ä¸ºæ¯«ç§’
                            duration_value = float(match.group(1))
                            duration_unit = match.group(2)
                            if duration_unit in ['s', 'ç§’']:
                                entities[entity_name] = duration_value * 1000
                            else:
                                entities[entity_name] = duration_value
                        else:
                            entities[entity_name] = value.strip()
                    except (ValueError, IndexError):
                        entities[entity_name] = value.strip()
        
        return entities
    
    @classmethod
    def _format_message(cls, message: str, content_types: List[str]) -> str:
        """
        æ™ºèƒ½æ ¼å¼åŒ–æ¶ˆæ¯ï¼Œæå‡å¯è¯»æ€§
        
        Args:
            message: åŸå§‹æ¶ˆæ¯
            content_types: å†…å®¹ç±»å‹åˆ—è¡¨
            
        Returns:
            æ ¼å¼åŒ–åçš„æ¶ˆæ¯
        """
        formatted = message
        
        # å¦‚æœåŒ…å«JSONï¼Œå°è¯•ç¾åŒ–
        if 'json' in content_types:
            try:
                import json as json_lib
                # æŸ¥æ‰¾JSONå†…å®¹å¹¶æ ¼å¼åŒ–
                for json_str in cls.JSON_PATTERN.findall(message):
                    try:
                        parsed = json_lib.loads(json_str)
                        pretty = json_lib.dumps(parsed, indent=2, ensure_ascii=False)
                        formatted = formatted.replace(json_str, f'\n{pretty}\n')
                    except:
                        pass
            except:
                pass
        
        # ç§»é™¤å¤šä½™ç©ºæ ¼
        formatted = ' '.join(formatted.split())
        
        return formatted
    
    @classmethod
    def _calculate_severity(cls, level: LogLevel, action_type: ActionType, message: str) -> int:
        """
        è®¡ç®—æ—¥å¿—ä¸¥é‡æ€§åˆ†æ•° (0-100)
        
        åˆ†æ•°è¶Šé«˜è¡¨ç¤ºè¶Šé‡è¦/ä¸¥é‡
        """
        score = 0
        
        # åŸºç¡€åˆ†æ•° - æ ¹æ®çº§åˆ«
        level_scores = {
            LogLevel.DEBUG: 10,
            LogLevel.INFO: 20,
            LogLevel.WARNING: 50,
            LogLevel.ERROR: 80,
            LogLevel.CRITICAL: 100
        }
        score += level_scores.get(level, 20)
        
        # æ“ä½œç±»å‹è°ƒæ•´
        if action_type == ActionType.ERROR:
            score += 20
        elif action_type == ActionType.DELETE:
            score += 10
        elif action_type == ActionType.AUTH:
            score += 15
        
        # å…³é”®è¯æ£€æµ‹
        critical_keywords = ['å¤±è´¥', 'failed', 'é”™è¯¯', 'error', 'å¼‚å¸¸', 'exception', 'å´©æºƒ', 'crash']
        if any(keyword in message.lower() for keyword in critical_keywords):
            score += 15
        
        # é™åˆ¶åœ¨ 0-100 èŒƒå›´
        return min(max(score, 0), 100)


class LogAggregator:
    """æ—¥å¿—èšåˆå™¨ - æä¾›æ‰¹é‡è§£æå’Œç»Ÿè®¡åŠŸèƒ½"""
    
    @staticmethod
    def parse_batch(lines: List[str]) -> List[Dict[str, Any]]:
        """æ‰¹é‡è§£ææ—¥å¿—è¡Œ"""
        return [LogParser.parse(line) for line in lines if line.strip()]
    
    @staticmethod
    def aggregate_stats(parsed_logs: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        èšåˆæ—¥å¿—ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            åŒ…å«å„ç§ç»Ÿè®¡æŒ‡æ ‡çš„å­—å…¸
        """
        if not parsed_logs:
            return {
                'total': 0,
                'by_level': {},
                'by_action': {},
                'by_module': {},
                'avg_severity': 0,
                'top_entities': {}
            }
        
        # æŒ‰çº§åˆ«ç»Ÿè®¡
        by_level = {}
        for log in parsed_logs:
            level = log['level']
            by_level[level] = by_level.get(level, 0) + 1
        
        # æŒ‰æ“ä½œç±»å‹ç»Ÿè®¡
        by_action = {}
        for log in parsed_logs:
            action = log['action_type']
            by_action[action] = by_action.get(action, 0) + 1
        
        # æŒ‰æ¨¡å—ç»Ÿè®¡
        by_module = {}
        for log in parsed_logs:
            module = log['module']
            by_module[module] = by_module.get(module, 0) + 1
        
        # å¹³å‡ä¸¥é‡æ€§
        avg_severity = sum(log['severity_score'] for log in parsed_logs) / len(parsed_logs)
        
        # æå–é«˜é¢‘å®ä½“
        entity_counts: Dict[str, Dict[Any, int]] = {}
        for log in parsed_logs:
            for entity_name, entity_value in log['entities'].items():
                if entity_name not in entity_counts:
                    entity_counts[entity_name] = {}
                entity_counts[entity_name][entity_value] = entity_counts[entity_name].get(entity_value, 0) + 1
        
        # è·å–æ¯ç§å®ä½“çš„ Top 5
        top_entities = {}
        for entity_name, counts in entity_counts.items():
            top_entities[entity_name] = sorted(
                counts.items(), 
                key=lambda x: x[1], 
                reverse=True
            )[:5]
        
        return {
            'total': len(parsed_logs),
            'by_level': by_level,
            'by_action': by_action,
            'by_module': by_module,
            'avg_severity': round(avg_severity, 2),
            'top_entities': top_entities
        }
    
    @staticmethod
    def find_related_logs(
        parsed_logs: List[Dict[str, Any]], 
        target_log: Dict[str, Any],
        context_size: int = 5
    ) -> List[Dict[str, Any]]:
        """
        æŸ¥æ‰¾ä¸ç›®æ ‡æ—¥å¿—ç›¸å…³çš„æ—¥å¿—
        
        Args:
            parsed_logs: æ‰€æœ‰å·²è§£æçš„æ—¥å¿—
            target_log: ç›®æ ‡æ—¥å¿—
            context_size: ä¸Šä¸‹æ–‡å¤§å°ï¼ˆå‰åå„Næ¡ï¼‰
            
        Returns:
            ç›¸å…³æ—¥å¿—åˆ—è¡¨
        """
        related = []
        
        # 1. æ—¶é—´ç›¸å…³ï¼ˆå‰åNæ¡ï¼‰
        try:
            target_idx = parsed_logs.index(target_log)
            start_idx = max(0, target_idx - context_size)
            end_idx = min(len(parsed_logs), target_idx + context_size + 1)
            related.extend(parsed_logs[start_idx:end_idx])
        except ValueError:
            pass
        
        # 2. å®ä½“ç›¸å…³ï¼ˆç›¸åŒçš„ message_id, rule_id ç­‰ï¼‰
        target_entities = target_log.get('entities', {})
        if target_entities:
            for log in parsed_logs:
                if log == target_log:
                    continue
                    
                log_entities = log.get('entities', {})
                # æ£€æŸ¥æ˜¯å¦æœ‰å…±åŒçš„å®ä½“
                common_entities = set(target_entities.items()) & set(log_entities.items())
                if common_entities and log not in related:
                    related.append(log)
        
        # å»é‡å¹¶æŒ‰æ—¶é—´æ’åº
        unique_related = {log['raw']: log for log in related}.values()
        return sorted(unique_related, key=lambda x: x['timestamp'])


# ä¾¿æ·å‡½æ•°
def parse_log_line(line: str) -> Dict[str, Any]:
    """è§£æå•è¡Œæ—¥å¿—çš„ä¾¿æ·å‡½æ•°"""
    return LogParser.parse(line)


def parse_log_lines(lines: List[str]) -> List[Dict[str, Any]]:
    """æ‰¹é‡è§£ææ—¥å¿—çš„ä¾¿æ·å‡½æ•°"""
    return LogAggregator.parse_batch(lines)

